{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb66df4",
   "metadata": {},
   "source": [
    "# Construindo Agentes\n",
    " \n",
    "> Nota: Opcionalmente, veja [estes slides](https://docs.google.com/presentation/d/13c0L1CQWAL7fuCXakOqjkvoodfynPJI4Hw_4H76okVU/edit?usp=sharing) e [langgraph_101.ipynb](langgraph_101.ipynb) para contexto antes de mergulhar neste notebook!\n",
    "\n",
    "Vamos construir um assistente de email do zero, come√ßando aqui com 1) a arquitetura do agente (usando [LangGraph](https://langchain-ai.github.io/langgraph/)) e seguindo com 2) testes (usando [LangSmith](https://docs.smith.langchain.com/)), 3) human-in-the-loop, e 4) mem√≥ria. Este diagrama mostra como essas pe√ßas se encaixam:\n",
    "\n",
    "![overview-img](img/overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d34429",
   "metadata": {},
   "source": [
    "#### Carregar vari√°veis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a69e9a",
   "metadata": {},
   "source": [
    "## Defini√ß√£o de Ferramentas\n",
    "\n",
    "Vamos come√ßar definindo algumas ferramentas simples que um assistente de email usar√° com o decorador `@tool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Escrever e enviar um email.\"\"\"\n",
    "    # Resposta placeholder - em aplica√ß√£o real enviaria email\n",
    "    return f\"Email enviado para {to} com assunto '{subject}' e conte√∫do: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Agendar uma reuni√£o no calend√°rio.\"\"\"\n",
    "    # Resposta placeholder - em aplica√ß√£o real verificaria calend√°rio e agendaria\n",
    "    date_str = preferred_day.strftime(\"%A, %d de %B de %Y\")\n",
    "    return f\"Reuni√£o '{subject}' agendada para {date_str} √†s {start_time}h por {duration_minutes} minutos com {len(attendees)} participantes\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Verificar disponibilidade do calend√°rio para um determinado dia.\"\"\"\n",
    "    # Resposta placeholder - em aplica√ß√£o real verificaria calend√°rio real\n",
    "    return f\"Hor√°rios dispon√≠veis em {day}: 9:00, 14:00, 16:00\"\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"Email foi enviado.\"\"\"\n",
    "      done: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911c929-5c41-4dcd-9cc8-21a8ff82b769",
   "metadata": {},
   "source": [
    "## Construindo nosso assistente de email\n",
    "\n",
    "Vamos combinar um [roteador e agente](https://langchain-ai.github.io/langgraph/tutorials/workflows/) para construir nosso assistente de email.\n",
    "\n",
    "![agent_workflow_img](img/email_workflow.png)\n",
    "\n",
    "### Roteador\n",
    "\n",
    "A etapa de roteamento lida com a decis√£o de triagem.\n",
    "\n",
    "O roteador de triagem foca apenas na decis√£o de triagem, enquanto o agente foca *apenas* na resposta.\n",
    "\n",
    "#### Estado\n",
    "\n",
    "Ao construir um agente, √© importante considerar as informa√ß√µes que voc√™ quer rastrear ao longo do tempo. Usaremos o objeto [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate) pr√©-constru√≠do do LangGraph, que √© apenas um dicion√°rio com uma chave `messages` que anexa mensagens retornadas por n√≥s [como sua l√≥gica de atualiza√ß√£o](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers). No entanto, o LangGraph oferece flexibilidade para rastrear outras informa√ß√µes. Definiremos um objeto `State` personalizado que estende `MessagesState` e adiciona uma chave `classification_decision`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692537ec-f09e-4086-81e4-9c517273b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    # Podemos adicionar uma chave espec√≠fica ao nosso estado para a entrada do email\n",
    "    email_input: dict\n",
    "    classification_decision: Literal[\"ignore\", \"respond\", \"notify\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd1647-6d58-4aae-b954-6a9c5790c20c",
   "metadata": {},
   "source": [
    "#### N√≥ de Triagem\n",
    "\n",
    "Definimos uma fun√ß√£o Python com nossa l√≥gica de roteamento de triagem.\n",
    "\n",
    "Para isso, usamos [sa√≠das estruturadas](https://python.langchain.com/docs/concepts/structured_outputs/) com um modelo Pydantic, que √© particularmente √∫til para definir esquemas de sa√≠da estruturados porque oferece dicas de tipo e valida√ß√£o. As descri√ß√µes no modelo Pydantic s√£o importantes porque s√£o passadas como parte do esquema JSON para o LLM para informar a coer√ß√£o de sa√≠da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf520b-adf5-4a7b-b7a8-b8c23720c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from email_assistant.utils import parse_email, format_email_markdown\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, default_triage_instructions, default_background\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c2ff0-da93-4731-b5b6-0ccd59e0e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(triage_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1ad2c-40a2-42d0-a4b8-7a25df825fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(triage_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0df31-b9d2-423f-ba07-67eb0643c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ea767-6ac1-4562-8ca6-5fa451495786",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_triage_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ae6a6-94d9-4160-8d45-18f4d29aa600",
   "metadata": {},
   "outputs": [],
   "source": "class RouterSchema(BaseModel):\n    \"\"\"Analyze the unread email and route it according to its content.\"\"\"\n\n    reasoning: str = Field(\n        description=\"Step-by-step reasoning behind the classification.\"\n    )\n    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n        description=\"The classification of an email: 'ignore' for irrelevant emails, \"\n        \"'notify' for important information that doesn't need a response, \"\n        \"'respond' for emails that need a reply\",\n    )\n\n# Initialize the LLM for use with router / structured output\nllm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0)\nllm_router = llm.with_structured_output(RouterSchema)\n\ndef triage_router(state: State) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\"\"\"\n\n    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n    system_prompt = triage_system_prompt.format(\n        background=default_background,\n        triage_instructions=default_triage_instructions\n    )\n\n    user_prompt = triage_user_prompt.format(\n        author=author, to=to, subject=subject, email_thread=email_thread\n    )\n\n    result = llm_router.invoke(\n        [\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ]\n    )\n\n    if result.classification == \"respond\":\n        print(\"üìß Classifica√ß√£o: RESPONDER - Este email requer uma resposta\")\n        goto = \"response_agent\"\n        update = {\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Responda ao email: \\n\\n{format_email_markdown(subject, author, to, email_thread)}\",\n                }\n            ],\n            \"classification_decision\": result.classification,\n        }\n\n    elif result.classification == \"ignore\":\n        print(\"üö´ Classifica√ß√£o: IGNORAR - Este email pode ser ignorado\")\n        goto = END\n        update =  {\n            \"classification_decision\": result.classification,\n        }\n\n    elif result.classification == \"notify\":\n        print(\"üîî Classifica√ß√£o: NOTIFICAR - Este email cont√©m informa√ß√µes importantes\")\n        # For now, we go to END. But we will add to this later!\n        goto = END\n        update = {\n            \"classification_decision\": result.classification,\n        }\n\n    else:\n        raise ValueError(f\"Classifica√ß√£o inv√°lida: {result.classification}\")\n    return Command(goto=goto, update=update)"
  },
  {
   "cell_type": "markdown",
   "id": "272d8715",
   "metadata": {},
   "source": [
    "Usamos objetos [Command](https://langchain-ai.github.io/langgraph/how-tos/command/) no LangGraph para tanto atualizar o estado quanto selecionar o pr√≥ximo n√≥ a visitar. Esta √© uma alternativa √∫til √†s arestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e842b3c-06f5-440f-8159-995503ef3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.tools.default.prompt_templates import AGENT_TOOLS_PROMPT\n",
    "from email_assistant.prompts import agent_system_prompt, default_response_preferences, default_cal_preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69c6fc-70aa-48f1-8312-2b1818469a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(AGENT_TOOLS_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052fced-3fdb-4cd2-ac88-e2ccdce14e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(agent_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools\n",
    "tools = [write_email, schedule_meeting, check_calendar_availability, Done]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM, enforcing tool use\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "def llm_call(state: State):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            # Invoke the LLM\n",
    "            llm_with_tools.invoke(\n",
    "                # Add the system prompt\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt.format(\n",
    "                        tools_prompt=AGENT_TOOLS_PROMPT,\n",
    "                        background=default_background,\n",
    "                        response_preferences=default_response_preferences,\n",
    "                        cal_preferences=default_cal_preferences,\n",
    "                    )}\n",
    "                ]\n",
    "                # Add the current messages to the prompt\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05d11a",
   "metadata": {},
   "source": [
    "#### N√≥ manipulador de ferramenta\n",
    "\n",
    "Depois que o LLM toma uma decis√£o, precisamos executar a ferramenta escolhida.\n",
    "\n",
    "O n√≥ `tool_handler` executa a ferramenta. Podemos ver que os n√≥s podem atualizar o estado do grafo para capturar qualquer informa√ß√£o necess√°ria. Neste caso, apenas adicionamos o resultado da ferramenta √†s mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_handler(state: State):\n",
    "    \"\"\"Performs the tool call.\"\"\"\n",
    "\n",
    "    # List for tool messages\n",
    "    result = []\n",
    "\n",
    "    # Iterate through tool calls\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Get the tool\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Run it\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Create a tool message\n",
    "        result.append({\"role\": \"tool\", \"content\" : observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "\n",
    "    # Add it to our messages\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721dede",
   "metadata": {},
   "source": [
    "#### Roteamento Condicional\n",
    "\n",
    "Nosso agente precisa decidir quando continuar usando ferramentas e quando parar. Esta fun√ß√£o de roteamento condicional direciona o agente para continuar ou terminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State) -> Literal[\"tool_handler\", \"__end__\"]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called.\"\"\"\n",
    "\n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # Check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"tool_handler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4ede8",
   "metadata": {},
   "source": [
    "#### Grafo do Agente\n",
    "\n",
    "Finalmente, podemos montar todos os componentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81df767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from email_assistant.utils import show_graph\n",
    "\n",
    "# Build workflow\n",
    "overall_workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "overall_workflow.add_node(\"llm_call\", llm_call)\n",
    "overall_workflow.add_node(\"tool_handler\", tool_handler)\n",
    "\n",
    "# Add edges\n",
    "overall_workflow.add_edge(START, \"llm_call\")\n",
    "overall_workflow.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_handler\": \"tool_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "overall_workflow.add_edge(\"tool_handler\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = overall_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f6373-bf48-44c2-ba33-000c9f22b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "show_graph(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8367c4",
   "metadata": {},
   "source": [
    "Isso cria um grafo que:\n",
    "1. Come√ßa com uma decis√£o do LLM\n",
    "2. Roteia condicionalmente para execu√ß√£o de ferramentas ou termina√ß√£o\n",
    "3. Ap√≥s execu√ß√£o de ferramentas, retorna ao LLM para a pr√≥xima decis√£o\n",
    "4. Repete at√© conclus√£o ou nenhuma ferramenta ser chamada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3406d-496d-43c9-942e-c5ce7e3a8321",
   "metadata": {},
   "source": [
    "### Combinar fluxo de trabalho com nosso agente\n",
    "\n",
    "Podemos combinar o roteador e o agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f2548-b5a5-4fb6-8aed-226369e53e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_workflow = (\n",
    "    StateGraph(State)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(\"response_agent\", agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6dcc4-6346-4d41-ae36-61f3fc83b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(overall_workflow, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091d5cc",
   "metadata": {},
   "source": [
    "Esta √© uma composi√ß√£o de n√≠vel superior onde:\n",
    "1. Primeiro, o roteador de triagem analisa o email\n",
    "2. Se necess√°rio, o agente de resposta cuida da elabora√ß√£o de uma resposta\n",
    "3. O fluxo de trabalho termina quando a triagem decide que nenhuma resposta √© necess√°ria ou o agente de resposta conclui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f18a6",
   "metadata": {},
   "outputs": [],
   "source": "email_input = {\n    \"author\": \"Admin do Sistema <sysadmin@empresa.com.br>\",\n    \"to\": \"Equipe de Desenvolvimento <dev@empresa.com.br>\",\n    \"subject\": \"Manuten√ß√£o programada - indisponibilidade do banco de dados\",\n    \"email_thread\": \"Ol√° pessoal,\\n\\nEste √© um lembrete de que realizaremos manuten√ß√£o programada no banco de dados de produ√ß√£o hoje √† noite das 2h √†s 4h. Durante este per√≠odo, todos os servi√ßos de banco de dados estar√£o indispon√≠veis.\\n\\nPor favor, planejem seu trabalho adequadamente e garantam que n√£o haja deployments cr√≠ticos programados durante esta janela.\\n\\nObrigado,\\nEquipe Admin do Sistema\"\n}\n\n# Run the agent\nresponse = overall_workflow.invoke({\"email_input\": email_input})\nfor m in response[\"messages\"]:\n    m.pretty_print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50ae0a-7bd1-4e69-90be-781b1e77b4dd",
   "metadata": {},
   "outputs": [],
   "source": "email_input = {\n  \"author\": \"Alice Silva <alice.silva@empresa.com.br>\",\n  \"to\": \"Jo√£o Santos <joao.santos@empresa.com.br>\",\n  \"subject\": \"D√∫vida r√°pida sobre documenta√ß√£o da API\",\n  \"email_thread\": \"Oi Jo√£o,\\n\\nEstava revisando a documenta√ß√£o da API para o novo servi√ßo de autentica√ß√£o e notei que alguns endpoints parecem estar faltando nas especifica√ß√µes. Pode me ajudar a esclarecer se isso foi intencional ou se devemos atualizar a documenta√ß√£o?\\n\\nEspecificamente, estou procurando:\\n- /auth/refresh\\n- /auth/validate\\n\\nObrigada!\\nAlice\"\n}\n\n# Run the agent\nresponse = overall_workflow.invoke({\"email_input\": email_input})\nfor m in response[\"messages\"]:\n    m.pretty_print()"
  },
  {
   "cell_type": "markdown",
   "id": "f631f61f",
   "metadata": {},
   "source": [
    "## Testando com Implanta√ß√£o Local\n",
    "\n",
    "Voc√™ pode encontrar o arquivo para nosso agente no diret√≥rio `src/email_assistant`:\n",
    "\n",
    "* `src/email_assistant/email_assistant.py`\n",
    "\n",
    "Voc√™ pode test√°-los localmente no LangGraph Studio executando:\n",
    "\n",
    "```\n",
    "! langgraph dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12752016",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Exemplo de e-mail que voc√™ pode testar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee005a",
   "metadata": {},
   "outputs": [],
   "source": "{\n  \"author\": \"Alice Silva <alice.silva@empresa.com.br>\",\n  \"to\": \"Jo√£o Santos <joao.santos@empresa.com.br>\",\n  \"subject\": \"D√∫vida r√°pida sobre documenta√ß√£o da API\",\n  \"email_thread\": \"Oi Jo√£o,\\n\\nEstava revisando a documenta√ß√£o da API para o novo servi√ßo de autentica√ß√£o e notei que alguns endpoints parecem estar faltando nas especifica√ß√µes. Pode me ajudar a esclarecer se isso foi intencional ou se devemos atualizar a documenta√ß√£o?\\n\\nEspecificamente, estou procurando:\\n- /auth/refresh\\n- /auth/validate\\n\\nObrigada!\\nAlice\"\n}"
  },
  {
   "cell_type": "markdown",
   "id": "d09e33b6",
   "metadata": {},
   "source": [
    "![studio-img](img/studio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d195e21-f2c5-4762-a4f0-c8d7459df6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}