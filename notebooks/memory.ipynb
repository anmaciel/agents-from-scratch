{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d047044f",
   "metadata": {},
   "source": [
    "# Agentes com Memória\n",
    "\n",
    "Temos um assistente de email que usa um roteador para triagem de emails e então passa o email para o agente gerar uma resposta. Também o avaliamos e adicionamos humano-no-loop (HITL). Mas e se nosso assistente pudesse **aprender** com as interações para melhorar ao longo do tempo? Isso é onde a **memória** entra.\n",
    "\n",
    "![overview-img](img/overview_memory.png)\n",
    "\n",
    "A memória no LangGraph opera em dois níveis distintos:\n",
    "\n",
    "**Memória Com Escopo de Thread (Curto prazo)** opera dentro dos limites de um único thread de conversa. É gerenciada automaticamente como parte do estado do grafo e persistida através de checkpoints com escopo de thread. Este tipo de memória retém histórico de conversa, arquivos enviados, documentos recuperados e outros artefatos gerados durante a interação. Pense nisso como a memória de trabalho que mantém contexto dentro de uma conversa específica, permitindo que o agente referencie mensagens ou ações anteriores sem começar do zero a cada vez.\n",
    "\n",
    "**Memória Através de Threads (Longo prazo)** se estende além de conversas individuais, criando uma base de conhecimento persistente que abrange múltiplas sessões. Esta memória é armazenada como documentos JSON em um armazenamento de memória, organizada por namespaces (como pastas) e chaves distintas (como nomes de arquivo). Diferente da memória com escopo de thread, esta informação persiste mesmo após as conversas terminarem, permitindo que o sistema se lembre de preferências do usuário, decisões passadas e conhecimento acumulado. Isso é o que permite que um agente verdadeiramente aprenda e se adapte ao longo do tempo, em vez de tratar cada interação como isolada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143094b4",
   "metadata": {},
   "source": [
    "#### Carregar Variáveis de Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99855af",
   "metadata": {},
   "source": [
    "## Memória no LangGraph\n",
    "\n",
    "### Memória Com Escopo de Thread e Através de Threads\n",
    "\n",
    "Primeiro, vale a pena explicar como [a memória funciona no LangGraph](https://langchain-ai.github.io/langgraph/concepts/memory/). LangGraph oferece dois tipos principais de memória:\n",
    "\n",
    "**Memória Com Escopo de Thread (Curto prazo)** opera dentro dos limites de um único thread de conversa. É gerenciada automaticamente como parte do estado do grafo e persistida através de checkpoints com escopo de thread. Este tipo de memória retém histórico de conversa, arquivos enviados, documentos recuperados e outros artefatos gerados durante a interação. Pense nisso como a memória de trabalho que mantém contexto dentro de uma conversa específica, permitindo que o agente referencie mensagens ou ações anteriores sem começar do zero a cada vez.\n",
    "\n",
    "**Memória Através de Threads (Longo prazo)** se estende além de conversas individuais, criando uma base de conhecimento persistente que abrange múltiplas sessões. Esta memória é armazenada como documentos JSON em um armazenamento de memória, organizada por namespaces (como pastas) e chaves distintas (como nomes de arquivo). Diferente da memória com escopo de thread, esta informação persiste mesmo após as conversas terminarem, permitindo que o sistema se lembre de preferências do usuário, decisões passadas e conhecimento acumulado. Isso é o que permite que um agente verdadeiramente aprenda e se adapte ao longo do tempo, em vez de tratar cada interação como isolada.\n",
    "\n",
    "Existem diferentes opções de armazenamento para memória através de threads:\n",
    "\n",
    "1. **Na Memória (ex. notebooks)**:\n",
    "   - Usa `from langgraph.store.memory import InMemoryStore`\n",
    "   - Simples e rápido para testes e desenvolvimento local\n",
    "2. **Desenvolvimento Local com `langgraph dev`**:\n",
    "   - Similar ao InMemoryStore mas com pseudo-persistência\n",
    "3. **LangGraph Platform ou Deployments de Produção**:\n",
    "   - Para deployments hospedados, você tem acesso a um armazenamento de produção\n",
    "\n",
    "Vamos usar o `InMemoryStore` aqui no notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb204c",
   "metadata": {},
   "source": [
    "As memórias são organizadas por namespace usando uma tupla, que neste exemplo específico será (`<user_id>`, \"memories\"). O namespace pode ter qualquer comprimento e representar qualquer coisa, não precisa ser específico do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0488a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8b303",
   "metadata": {},
   "source": [
    "Usamos o método `store.put` para salvar memórias em nosso namespace no armazenamento. Quando fazemos isso, especificamos o namespace, como definido acima, e um par chave-valor para a memória: a chave é simplesmente um identificador único para a memória (memory_id) e o valor (um dicionário) é a própria memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af95b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60408492",
   "metadata": {},
   "source": [
    "Podemos ler as memórias em nosso namespace usando o método `store.search`, que retornará todas as memórias para um usuário específico como uma lista. A memória mais recente é a última da lista. Cada tipo de memória é uma classe Python (`Item`) com certos atributos. Podemos acessá-la como um dicionário convertendo via `.dict`. Os atributos que possui são mostrados abaixo, mas o mais importante geralmente é `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "memories[-1].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3e781",
   "metadata": {},
   "source": [
    "Para usar isso em um grafo, tudo que precisamos fazer é compilar o grafo com o store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need this because we want to enable threads (conversations)\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "checkpointer = InMemorySaver()\n",
    "# We need this because we want to enable across-thread memory\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()\n",
    "# Compile the graph with the checkpointer and store\n",
    "# graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982928",
   "metadata": {},
   "source": [
    "Vamos pegar nosso grafo com HITL e adicionar memória a ele. Isso será muito similar ao que tínhamos anteriormente. Simplesmente atualizaremos a memória no store quando recebermos feedback do usuário.\n",
    "\n",
    "A principal diferença será adicionar um [LangGraph Store](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory) para persistir as memórias.\n",
    "\n",
    "## Memória\n",
    "\n",
    "Vamos implementar memória que captura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38308fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, agent_system_prompt_hitl_memory, default_triage_instructions, default_background, default_response_preferences, default_cal_preferences, MEMORY_UPDATE_INSTRUCTIONS, MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT\n",
    "from email_assistant.tools.default.prompt_templates import HITL_MEMORY_TOOLS_PROMPT\n",
    "from email_assistant.schemas import State, RouterSchema, StateInput\n",
    "from email_assistant.utils import parse_email, format_for_display, format_email_markdown\n",
    "\n",
    "# Agent tools\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "class Question(BaseModel):\n",
    "      \"\"\"Question to ask user.\"\"\"\n",
    "      content: str\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool\n",
    "\n",
    "# All tools available to the agent\n",
    "tools = [\n",
    "    write_email,\n",
    "    schedule_meeting,\n",
    "    check_calendar_availability,\n",
    "    Question,\n",
    "    Done\n",
    "]\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema)\n",
    "\n",
    "# Initialize the LLM, enforcing tool use (of any available tools) for agent\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03538f56",
   "metadata": {},
   "source": [
    "Agora, esta é a parte crítica! Atualmente não capturamos nenhum feedback do usuário em nosso grafo.\n",
    "\n",
    "### Gerenciamento de Memória\n",
    "\n",
    "O que *queremos* fazer é bastante direto: queremos adicionar o feedback ao `Store` de memória. Se compilarmos nosso grafo com o `Store`, podemos acessá-lo em qualquer nó. Então vamos modificar o `interrupt_handler` para salvar o feedback do usuário no `Store`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2715152-2d19-4449-be4b-fdc602eee52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(default_triage_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ab99d-bc21-4cf7-a58a-261e82920566",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_cal_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd98f1-15a7-4fbb-8cce-cbbb0503d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_response_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(store, namespace, default_content=None):\n",
    "    \"\"\"Get memory from the store or initialize with default if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        store: LangGraph BaseStore instance to search for existing memory\n",
    "        namespace: Tuple defining the memory namespace, e.g. (\"email_assistant\", \"triage_preferences\")\n",
    "        default_content: Default content to use if memory doesn't exist\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the memory profile, either from existing memory or the default\n",
    "    \"\"\"\n",
    "    # Search for existing memory with namespace and key\n",
    "    user_preferences = store.get(namespace, \"user_preferences\")\n",
    "\n",
    "    # If memory exists, return its content (the value)\n",
    "    if user_preferences:\n",
    "        return user_preferences.value\n",
    "\n",
    "    # If memory doesn't exist, add it to the store and return the default content\n",
    "    else:\n",
    "        # Namespace, key, value\n",
    "        store.put(namespace, \"user_preferences\", default_content)\n",
    "        user_preferences = default_content\n",
    "\n",
    "    # Return the default content\n",
    "    return user_preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5181e6",
   "metadata": {},
   "source": [
    "Para 2) atualizar memória, podemos usar alguns truques do [guia de prompting GPT-4.1](https://cookbook.openai.com/examples/gpt4-1_prompting_guide) para nos ajudar a atualizar a memória:\n",
    "\n",
    "1. **Instruções detalhadas**: Fornecer instruções específicas sobre como atualizar preferências\n",
    "2. **Exemplos**: Mostrar exemplos de atualizações de memória bem formatadas  \n",
    "3. **Reforço**: Usar lembretes para garantir que as instruções sejam seguidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Markdown(MEMORY_UPDATE_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8aa70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPreferences(BaseModel):\n",
    "    \"\"\"Updated user preferences based on user's feedback.\"\"\"\n",
    "    chain_of_thought: str = Field(description=\"Reasoning about which user preferences need to add / update if required\")\n",
    "    user_preferences: str = Field(description=\"Updated user preferences\")\n",
    "\n",
    "def update_memory(store, namespace, messages):\n",
    "    \"\"\"Update memory profile in the store.\n",
    "\n",
    "    Args:\n",
    "        store: LangGraph BaseStore instance to update memory\n",
    "        namespace: Tuple defining the memory namespace, e.g. (\"email_assistant\", \"triage_preferences\")\n",
    "        messages: List of messages to update the memory with\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the existing memory\n",
    "    user_preferences = store.get(namespace, \"user_preferences\")\n",
    "\n",
    "    # Update the memory\n",
    "    llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0).with_structured_output(UserPreferences)\n",
    "    result = llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": MEMORY_UPDATE_INSTRUCTIONS.format(current_profile=user_preferences.value, namespace=namespace)},\n",
    "        ] + messages\n",
    "    )\n",
    "\n",
    "    # Save the updated memory to the store\n",
    "    store.put(namespace, \"user_preferences\", result.user_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af20960",
   "metadata": {},
   "source": [
    "Configuramos o roteador de triagem como tínhamos antes, com uma pequena mudança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a789ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_router(state: State, store: BaseStore) -> Command[Literal[\"triage_interrupt_handler\", \"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\n",
    "\n",
    "    The triage step prevents the assistant from wasting time on:\n",
    "    - Marketing emails and spam\n",
    "    - Company-wide announcements\n",
    "    - Messages meant for other teams\n",
    "    \"\"\"\n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification\n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Search for existing triage_preferences memory\n",
    "    triage_instructions = get_memory(store, (\"email_assistant\", \"triage_preferences\"), default_triage_instructions)\n",
    "\n",
    "    # Format system prompt with background and triage instructions\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=triage_instructions,\n",
    "    )\n",
    "\n",
    "    # Run the router LLM\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Decision\n",
    "    classification = result.classification\n",
    "\n",
    "    # Process the classification decision\n",
    "    if classification == \"respond\":\n",
    "        print(\"📧 Classificação: RESPONDER - Este email requer uma resposta\")\n",
    "        # Next node\n",
    "        goto = \"response_agent\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": result.classification,\n",
    "            \"messages\": [{\"role\": \"user\",\n",
    "                            \"content\": f\"Respond to the email: {email_markdown}\"\n",
    "                        }],\n",
    "        }\n",
    "\n",
    "    elif classification == \"ignore\":\n",
    "        print(\"🚫 Classificação: IGNORAR - Este email pode ser ignorado\")\n",
    "\n",
    "        # Next node\n",
    "        goto = END\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    elif classification == \"notify\":\n",
    "        print(\"🔔 Classificação: NOTIFICAR - Este email contém informações importantes\")\n",
    "\n",
    "        # Next node\n",
    "        goto = \"triage_interrupt_handler\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {classification}\")\n",
    "\n",
    "    return Command(goto=goto, update=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be4d63",
   "metadata": {},
   "source": [
    "Precisamos apenas fazer uma pequena alteração no manipulador de interrupção para atualizar a memória quando o usuário fornecer feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ef46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_interrupt_handler(state: State, store: BaseStore) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Handles interrupts from the triage step\"\"\"\n",
    "\n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification\n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Create messages\n",
    "    messages = [{\"role\": \"user\",\n",
    "                \"content\": f\"Email to notify user about: {email_markdown}\"\n",
    "                }]\n",
    "\n",
    "    # Create interrupt for Agent Inbox\n",
    "    request = {\n",
    "        \"action_request\": {\n",
    "            \"action\": f\"Email Assistant: {state['classification_decision']}\",\n",
    "            \"args\": {}\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"allow_ignore\": True,\n",
    "            \"allow_respond\": True,\n",
    "            \"allow_edit\": False,\n",
    "            \"allow_accept\": False,\n",
    "        },\n",
    "        # Email to show in Agent Inbox\n",
    "        \"description\": email_markdown,\n",
    "    }\n",
    "\n",
    "    # Send to Agent Inbox and wait for response\n",
    "    response = interrupt([request])[0]\n",
    "\n",
    "    # If user provides feedback, go to response agent and use feedback to respond to email\n",
    "    if response[\"type\"] == \"response\":\n",
    "        # Add feedback to messages\n",
    "        user_input = response[\"args\"]\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"User wants to reply to the email. Use this feedback to respond: {user_input}\"\n",
    "                        })\n",
    "        # This is new: update triage_preferences with feedback\n",
    "        update_memory(store, (\"email_assistant\", \"triage_preferences\"), [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The user decided to respond to the email, so update the triage preferences to capture this.\"\n",
    "        }] + messages)\n",
    "\n",
    "        goto = \"response_agent\"\n",
    "\n",
    "    # If user ignores email, go to END\n",
    "    elif response[\"type\"] == \"ignore\":\n",
    "        # Make note of the user's decision to ignore the email\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"The user decided to ignore the email even though it was classified as notify. Update triage preferences to capture this.\"\n",
    "                        })\n",
    "        # This is new: triage_preferences with feedback\n",
    "        update_memory(store, (\"email_assistant\", \"triage_preferences\"), messages)\n",
    "        goto = END\n",
    "\n",
    "    # Catch all other responses\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid response: {response}\")\n",
    "\n",
    "    # Update the state\n",
    "    update = {\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd428f5",
   "metadata": {},
   "source": [
    "Agora que temos os gerenciadores de memória configurados, podemos usar as preferências armazenadas ao gerar respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: State, store: BaseStore):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    # Search for existing cal_preferences memory\n",
    "    cal_preferences = get_memory(store, (\"email_assistant\", \"cal_preferences\"), default_cal_preferences)\n",
    "\n",
    "    # Search for existing response_preferences memory\n",
    "    response_preferences = get_memory(store, (\"email_assistant\", \"response_preferences\"), default_response_preferences)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt_hitl_memory.format(tools_prompt=HITL_MEMORY_TOOLS_PROMPT,\n",
    "                                                                                         background=default_background,\n",
    "                                                                                         response_preferences=response_preferences,\n",
    "                                                                                         cal_preferences=cal_preferences)}\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60aff5d",
   "metadata": {},
   "source": [
    "### Integração de Memória no Manipulador de Interrupção\n",
    "\n",
    "Da mesma forma, adicionaremos memória ao manipulador de interrupção!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrupt_handler(state: State, store: BaseStore) -> Command[Literal[\"llm_call\", \"__end__\"]]:\n",
    "    \"\"\"Creates an interrupt for human review of tool calls\"\"\"\n",
    "\n",
    "    # Store messages\n",
    "    result = []\n",
    "\n",
    "    # Go to the LLM call node next\n",
    "    goto = \"llm_call\"\n",
    "\n",
    "    # Iterate over the tool calls in the last message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "\n",
    "        # Allowed tools for HITL\n",
    "        hitl_tools = [\"write_email\", \"schedule_meeting\", \"Question\"]\n",
    "\n",
    "        # If tool is not in our HITL list, execute it directly without interruption\n",
    "        if tool_call[\"name\"] not in hitl_tools:\n",
    "\n",
    "            # Execute tool without interruption\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "            continue\n",
    "\n",
    "        # Get original email from email_input in state\n",
    "        email_input = state[\"email_input\"]\n",
    "        author, to, subject, email_thread = parse_email(email_input)\n",
    "        original_email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "        # Format tool call for display and prepend the original email\n",
    "        tool_display = format_for_display(tool_call)\n",
    "        description = original_email_markdown + tool_display\n",
    "\n",
    "        # Configure what actions are allowed in Agent Inbox\n",
    "        if tool_call[\"name\"] == \"write_email\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"Question\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": False,\n",
    "                \"allow_accept\": False,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Create the interrupt request\n",
    "        request = {\n",
    "            \"action_request\": {\n",
    "                \"action\": tool_call[\"name\"],\n",
    "                \"args\": tool_call[\"args\"]\n",
    "            },\n",
    "            \"config\": config,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "        # Send to Agent Inbox and wait for response\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        # Handle the responses\n",
    "        if response[\"type\"] == \"accept\":\n",
    "\n",
    "            # Execute the tool with original args\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "\n",
    "        elif response[\"type\"] == \"edit\":\n",
    "\n",
    "            # Tool selection\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            initial_tool_call = tool_call[\"args\"]\n",
    "\n",
    "            # Get edited args from Agent Inbox\n",
    "            edited_args = response[\"args\"][\"args\"]\n",
    "\n",
    "            # Update the AI message's tool call with edited content (reference to the message in the state)\n",
    "            ai_message = state[\"messages\"][-1] # Get the most recent message from the state\n",
    "            current_id = tool_call[\"id\"] # Store the ID of the tool call being edited\n",
    "\n",
    "            # Create a new list of tool calls by filtering out the one being edited and adding the updated version\n",
    "            # This avoids modifying the original list directly (immutable approach)\n",
    "            updated_tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "            ]\n",
    "\n",
    "            # Create a new copy of the message with updated tool calls rather than modifying the original\n",
    "            # This ensures state immutability and prevents side effects in other parts of the code\n",
    "            # When we update the messages state key (\"messages\": result), the add_messages reducer will\n",
    "            # overwrite existing messages by id and we take advantage of this here to update the tool calls.\n",
    "            result.append(ai_message.model_copy(update={\"tool_calls\": updated_tool_calls}))\n",
    "\n",
    "            # Save feedback in memory and update the write_email tool call with the edited content from Agent Inbox\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "\n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "\n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"response_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User edited the email response. Here is the initial email generated by the assistant: {initial_tool_call}. Here is the edited email: {edited_args}. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            # Save feedback in memory and update the schedule_meeting tool call with the edited content from Agent Inbox\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "\n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "\n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"cal_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User edited the calendar invitation. Here is the initial calendar invitation generated by the assistant: {initial_tool_call}. Here is the edited calendar invitation: {edited_args}. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            # Catch all other tool calls\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"ignore\":\n",
    "\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this email draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the email draft. That means they did not want to respond to the email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this calendar meeting draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the calendar meeting draft. That means they did not want to schedule a meeting for this email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this question. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the Question. That means they did not want to answer the question or deal with this email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"response\":\n",
    "            # User provided feedback\n",
    "            user_feedback = response[\"args\"]\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the email. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"response_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User gave feedback, which we can use to update the response preferences. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the meeting request. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"cal_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User gave feedback, which we can use to update the calendar preferences. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User answered the question, which can we can use for any follow up actions. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "    # Update the state\n",
    "    update = {\n",
    "        \"messages\": result,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedcaec",
   "metadata": {},
   "source": [
    "O resto é igual ao anterior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.utils import show_graph\n",
    "\n",
    "# Conditional edge function\n",
    "def should_continue(state: State, store: BaseStore) -> Literal[\"interrupt_handler\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"interrupt_handler\"\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes - with store parameter\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"interrupt_handler\", interrupt_handler)\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"interrupt_handler\": \"interrupt_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the agent\n",
    "response_agent = agent_builder.compile()\n",
    "\n",
    "# Build overall workflow with store and checkpointer\n",
    "overall_workflow = (\n",
    "    StateGraph(State, input=StateInput)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(triage_interrupt_handler)\n",
    "    .add_node(\"response_agent\", response_agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ")\n",
    "\n",
    "email_assistant = overall_workflow.compile()\n",
    "show_graph(email_assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43747219",
   "metadata": {},
   "source": [
    "## Testando o agente com memória\n",
    "\n",
    "Agora que implementamos memória em nosso assistente de email, vamos testar como o sistema aprende com o feedback do usuário e se adapta ao longo do tempo. Esta seção de testes explora como diferentes tipos de interações do usuário criam atualizações de memória distintas que melhoram o desempenho futuro do assistente.\n",
    "\n",
    "As principais questões que estamos respondendo através destes testes:\n",
    "1. Como o sistema captura e armazena as preferências do usuário?\n",
    "2. Como essas preferências armazenadas afetam decisões futuras?\n",
    "3. Quais padrões de interação levam a que tipos de atualizações de memória?\n",
    "\n",
    "Primeiro, vamos construir uma função auxiliar para exibir o conteúdo da memória para que possamos acompanhar como ela evolui ao longo de nossos testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59079929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Helper function to display memory content\n",
    "def display_memory_content(store, namespace=None):\n",
    "    # Display current memory content for all namespaces\n",
    "    print(\"\\n======= CURRENT MEMORY CONTENT =======\")\n",
    "    if namespace:\n",
    "        memory = store.get(namespace, \"user_preferences\")\n",
    "        if memory:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print(memory.value)\n",
    "        else:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print(\"Nenhuma memória encontrada\")\n",
    "    else:\n",
    "        for namespace in [\n",
    "            (\"email_assistant\", \"triage_preferences\"),\n",
    "            (\"email_assistant\", \"response_preferences\"),\n",
    "            (\"email_assistant\", \"cal_preferences\"),\n",
    "            (\"email_assistant\", \"background\")\n",
    "        ]:\n",
    "            memory = store.get(namespace, \"user_preferences\")\n",
    "            if memory:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print(memory.value)\n",
    "            else:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print(\"Nenhuma memória encontrada\")\n",
    "            print(\"=======================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397114bf",
   "metadata": {},
   "source": [
    "### Aceitar `write_email` e `schedule_meeting`\n",
    "\n",
    "Nosso primeiro teste examina o que acontece quando um usuário aceita as ações do agente sem modificação. Este caso base nos ajuda a entender como o sistema se comporta quando nenhum feedback é fornecido:\n",
    "\n",
    "1. Usaremos o mesmo email de planejamento tributário de nossos testes anteriores\n",
    "2. O sistema o classificará como \"RESPOND\" e proporá agendar uma reunião\n",
    "3. Aceitaremos o agendamento da reunião sem mudanças\n",
    "4. O agente gerará um email confirmando a reunião\n",
    "5. Aceitaremos o email sem mudanças\n",
    "\n",
    "Este teste demonstra o comportamento padrão de nosso sistema habilitado para memória. Quando um usuário simplesmente aceita ações propostas, esperamos atualizações mínimas ou nenhuma atualização de memória, já que não há feedback explícito do qual aprender. No entanto, o sistema ainda utilizará a memória existente (se houver) ao gerar suas respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649cee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "# Email will be classified as \"respond\"\n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Executando o grafo até a primeira interrupção...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e199e",
   "metadata": {},
   "source": [
    "Aceitar a chamada de ferramenta `schedule_meeting`\n",
    "\n",
    "Ao examinarmos a proposta inicial de `schedule_meeting`, observe como o sistema usa a memória existente para informar suas decisões:\n",
    "\n",
    "1. As preferências padrão de calendário mostram uma preferência por reuniões de 30 minutos, embora o email solicite 45 minutos\n",
    "2. O agente ainda propõe uma reunião de 45 minutos, respeitando a solicitação específica do remetente\n",
    "3. Aceitamos esta proposta sem modificação para ver se a simples aceitação desencadeia alguma atualização de memória\n",
    "\n",
    "Após executar este passo, verificaremos o conteúdo da memória para confirmar se a aceitação sozinha leva a atualizações de memória. A simples aceitação representa a experiência base do usuário - o sistema funciona conforme pretendido sem exigir ajustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usuário aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b80f99",
   "metadata": {},
   "source": [
    "Aceitar a chamada de ferramenta `write_email`\n",
    "\n",
    "Agora aceitaremos o rascunho de email que confirma o agendamento da reunião:\n",
    "\n",
    "1. O rascunho de email é gerado com conhecimento de nossas preferências de calendário\n",
    "2. Ele inclui detalhes sobre o horário da reunião, duração e propósito\n",
    "3. Aceitaremos sem mudanças para completar o caso de teste base\n",
    "\n",
    "Após aceitar, verificaremos todos os armazenamentos de memória para ver se ocorreram atualizações. Como esperado, simplesmente aceitar as propostas do agente não fornece sinais de aprendizado fortes - não há feedback claro sobre o que o usuário gosta ou não gosta da abordagem do agente.\n",
    "\n",
    "O link de rastreamento mostra a execução completa do fluxo de trabalho, onde podemos ver que a memória é usada na chamada LLM para geração de resposta, mas nenhuma atualização de memória ocorre, que é o comportamento esperado para simples aceitações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12035cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usuário aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting the write_email tool call\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc178d",
   "metadata": {},
   "source": [
    "Podemos olhar as mensagens completas e o rastreamento: \n",
    "\n",
    "https://smith.langchain.com/public/86ff6474-29fe-452e-8829-b05a91b458eb/r\n",
    "\n",
    "Você notará que a memória é usada na chamada LLM para responder. \n",
    "\n",
    "Mas o armazenamento de memória *não* é atualizado, porque não adicionamos nenhum feedback via HITL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58201a21",
   "metadata": {},
   "source": [
    "### Editar `write_email` e `schedule_meeting`\n",
    "\n",
    "Este teste explora como o sistema aprende a partir de edições diretas às suas ações propostas. Quando usuários modificam as sugestões do agente, isso cria sinais de aprendizado claros e específicos sobre suas preferências:\n",
    "\n",
    "1. Usaremos o mesmo email de planejamento tributário de antes\n",
    "2. Quando o agente propor uma reunião de 45 minutos, editaremos para:\n",
    "   - Mudar a duração para 30 minutos (correspondendo à nossa preferência armazenada)\n",
    "   - Tornar o assunto mais conciso\n",
    "3. Quando o agente rascunhar um email, editaremos para ser:\n",
    "   - Mais curto e menos formal\n",
    "   - Estruturado de forma diferente\n",
    "\n",
    "Edições fornecem o feedback mais explícito sobre preferências do usuário, permitindo que o sistema aprenda exatamente quais mudanças são desejadas. Esperamos ver atualizações específicas e direcionadas em nossos armazenamentos de memória que reflitam essas edições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same email as before\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_2 = uuid.uuid4()\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# Run the graph until the first interrupt - will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "print(\"Executando o grafo até a primeira interrupção...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_2):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73ba71",
   "metadata": {},
   "source": [
    "Editar a chamada da ferramenta `schedule_meeting`\n",
    "\n",
    "Quando editamos a proposta de reunião, estamos fornecendo feedback direto e explícito sobre nossas preferências. Isso cria uma oportunidade significativa de aprendizado para o sistema:\n",
    "\n",
    "1. O agente inicialmente propõe uma reunião de 45 minutos (a duração solicitada no email)\n",
    "2. Nós editamos para 30 minutos e simplificamos o assunto de \"Tax Planning Strategies Discussion\" para \"Tax Planning Discussion\"\n",
    "3. Isso cria feedback claro e específico sobre nossas preferências de tempo e convenções de nomenclatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af760977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the schedule_meeting tool call\n",
    "print(\"\\nSimulando usuário editando a schedule_meeting chamada de ferramenta...\")\n",
    "edited_schedule_args = {\n",
    "    \"attendees\": [\"pm@client.com\", \"lance@company.com\"],\n",
    "    \"subject\": \"Tax Planning Discussion\",\n",
    "    \"duration_minutes\": 30, # Changed from 45 to 30\n",
    "    \"preferred_day\": \"2025-04-22\",\n",
    "    \"start_time\": 14\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_schedule_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing schedule_meeting\n",
    "print(\"\\nVerificando memória após editar schedule_meeting:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb324f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "{'preferences': '\\n30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'}\n",
    "```\n",
    "\n",
    "```\n",
    "{'preferences': \"30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n\\nUser prefers 30 minute meetings over longer durations such as 45 minutes. When scheduling, default to 30 minutes unless otherwise specified. Subject lines should be concise (e.g., 'Tax Planning Discussion' instead of 'Tax Planning Strategies Discussion').\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc585a",
   "metadata": {},
   "source": [
    "Olhando para a memória após editar o convite de calendário, podemos ver que ela foi atualizada:\n",
    "\n",
    "1. O sistema identificou que preferimos reuniões de 30 minutos em vez de durações mais longas\n",
    "2. Também capturou nossa preferência por assuntos de reunião concisos\n",
    "\n",
    "O que é particularmente impressionante sobre esta atualização de memória é:\n",
    "- Ela não apenas registra nossa edição específica, mas generaliza para um padrão de preferência mais amplo\n",
    "- Preserva todo o conteúdo de memória existente enquanto adiciona a nova informação\n",
    "- Extrai múltiplos sinais de preferência de uma única interação de edição\n",
    "\n",
    "Agora, vamos editar o rascunho de email para ver como o sistema captura diferentes tipos de preferências de comunicação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))\n",
    "# Now simulate user editing the write_email tool call\n",
    "print(\"\\nSimulando usuário editando a write_email chamada de ferramenta...\")\n",
    "edited_email_args = {\n",
    "    \"to\": \"pm@client.com\",\n",
    "    \"subject\": \"Re: Tax season let's schedule call\",\n",
    "    \"content\": \"Thanks! I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\\n\\nBest regards,\\nLance Martin\"\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_email_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing write_email\n",
    "print(\"\\nVerificando memória após editar write_email:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbd5f9",
   "metadata": {},
   "source": [
    "Nossa edição de email revela capacidades de aprendizado ainda mais sofisticadas:\n",
    "\n",
    "1. Encurtamos e simplificamos drasticamente o conteúdo do email\n",
    "2. Mudamos o tom para ser mais casual\n",
    "3. Adicionamos uma pergunta pedindo confirmação em vez de assumir que o horário funciona\n",
    "4. Alteramos ligeiramente os detalhes da reunião (dia e horário)\n",
    "\n",
    "Olhando para a memória atualizada, podemos ver que o sistema extraiu uma percepção chave sobre nosso estilo de comunicação:\n",
    "\n",
    "```\n",
    "Ao agendar uma reunião, peça ao destinatário para confirmar se o horário proposto funciona para eles, em vez de assumir e declarar que a reunião já está agendada.\n",
    "```\n",
    "\n",
    "Isso demonstra a capacidade do sistema de:\n",
    "- Analisar nossa edição não apenas em um nível superficial, mas para entender a intenção\n",
    "- Extrair princípios generalizáveis de exemplos específicos\n",
    "- Preservar toda a orientação existente enquanto adiciona novas percepções\n",
    "- Manter a organização e estrutura da memória\n",
    "\n",
    "Essas atualizações de memória direcionadas e de alta qualidade melhorarão todas as interações futuras sem exigir correções repetidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_2)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92a42b",
   "metadata": {},
   "source": [
    "### Responder (com feedback) `write_email` e `schedule_meeting`\n",
    "\n",
    "Nosso conjunto final de testes explora o padrão de feedback \"resposta\" - fornecendo orientação sem editar ou aceitar diretamente. Este mecanismo de feedback conversacional oferece um meio-termo entre aceitação e edição:\n",
    "\n",
    "1. Primeiro, testaremos feedback para agendamento de reunião solicitando:\n",
    "   - Duração mais curta (30 minutos em vez de 45)\n",
    "   - Horários de reunião à tarde (após às 14h)\n",
    "   \n",
    "2. Em seguida, testaremos feedback para rascunho de email solicitando:\n",
    "   - Linguagem mais curta e menos formal\n",
    "   - Uma declaração de encerramento específica sobre esperar pela reunião\n",
    "   \n",
    "3. Finalmente, testaremos feedback para perguntas fornecendo:\n",
    "   - Uma resposta direta com contexto adicional\n",
    "   - Preferências específicas (local de brunch, horário)\n",
    "\n",
    "Esta abordagem de feedback em linguagem natural permite que usuários orientem o assistente sem ter que fazer o trabalho eles mesmos. Esperamos ver atualizações detalhadas de memória que extraiam os princípios gerais de nosso feedback específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07676231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_5 = uuid.uuid4()\n",
    "thread_config_5 = {\"configurable\": {\"thread_id\": thread_id_5}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "# Email will be classified as \"respond\"\n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Executando o grafo até a primeira interrupção...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store, (\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fc45d",
   "metadata": {},
   "source": [
    "Fornecer feedback para a chamada de ferramenta `schedule_meeting`\n",
    "\n",
    "Em vez de editar diretamente a proposta de reunião ou simplesmente aceitá-la, forneceremos feedback em linguagem natural:\n",
    "\n",
    "1. Solicitamos uma reunião de 30 minutos em vez de 45 minutos\n",
    "2. Expressamos uma preferência por reuniões à tarde após às 14h\n",
    "3. O sistema deve interpretar este feedback e gerar uma nova proposta\n",
    "\n",
    "Esta abordagem conversacional é frequentemente mais natural e eficiente do que edição direta, especialmente para usuários móveis ou aqueles que preferem dar direção de alto nível em vez de edições detalhadas.\n",
    "\n",
    "Após fornecer feedback, examinaremos a memória de preferências de calendário para ver como esta orientação em linguagem natural é capturada. Esperamos ver o sistema extrair tanto a duração da reunião quanto as preferências de horário do dia como princípios gerais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a151f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usuário fornecendo feedback para a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for schedule_meeting\n",
    "print(\"\\nVerificando memória após fornecer feedback para schedule_meeting:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088757c",
   "metadata": {},
   "source": [
    "Nossa verificação de memória após fornecer feedback mostra uma atualização elegantemente simples de preferência de calendário:\n",
    "\n",
    "```\n",
    "Reuniões de 30 minutos são preferidas, mas reuniões de 15 minutos também são aceitáveis.\n",
    "Reuniões à tarde após às 14h são preferidas.\n",
    "```\n",
    "\n",
    "O sistema:\n",
    "1. Capturou ambos os aspectos do nosso feedback (duração e horário do dia)\n",
    "2. Preservou a preferência existente sobre reuniões de 15 minutos\n",
    "3. Adicionou nossa preferência por reuniões à tarde após às 14h como uma nova linha\n",
    "4. Manteve o formato limpo e legível\n",
    "\n",
    "Este mecanismo de feedback em linguagem natural cria a mesma qualidade de atualizações de memória que a edição direta, mas requer menos esforço do usuário. O sistema é capaz de extrair preferências estruturadas de feedback não estruturado, mostrando sua capacidade de aprender a partir de interações conversacionais.\n",
    "\n",
    "Vamos aceitar esta proposta de reunião revisada e passar para o rascunho de email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usuário aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting schedule_meeting after feedback\n",
    "print(\"\\nVerificando memória após aceitar schedule_meeting após feedback:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ede94",
   "metadata": {},
   "source": [
    "Agora fornecer feedback para a chamada de ferramenta `write_email`\n",
    "\n",
    "Similar ao nosso feedback de reunião, agora forneceremos orientação em linguagem natural para o rascunho de email:\n",
    "\n",
    "1. Solicitamos linguagem \"mais curta e menos formal\" - uma preferência de estilo\n",
    "2. Pedimos uma declaração de encerramento específica sobre esperar pela reunião\n",
    "3. O sistema deve interpretar esta orientação e reescrever o email adequadamente\n",
    "\n",
    "Após fornecer este feedback, verificaremos a memória de preferências de resposta para ver como essas preferências de estilo e estrutura são capturadas. Esperamos ver diretrizes generalizáveis sobre brevidade, formalidade e declarações de encerramento adicionadas ao nosso perfil de preferências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usuário fornecendo feedback para a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"}]), config=thread_config_5):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for write_email\n",
    "print(\"\\nVerificando memória após fornecer feedback para write_email:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b360a2",
   "metadata": {},
   "source": [
    "A atualização de memória após nosso feedback de email mostra aprendizado altamente sofisticado sobre preferências tanto de agendamento de reunião quanto de escrita de email:\n",
    "\n",
    "1. O sistema adicionou uma seção completamente nova às preferências de resposta intitulada \"Ao escrever respostas de email\" com duas preferências principais:\n",
    "   - \"Favoreça linguagem mais curta e menos formal quando possível, a menos que o contexto exija formalidade\"\n",
    "   - \"Inclua uma declaração de encerramento expressando que você espera pela reunião ou conversa ao confirmar compromissos\"\n",
    "\n",
    "2. Também adicionou um novo ponto à seção \"Ao responder a solicitações de agendamento de reunião\":\n",
    "   - \"Ao agendar reuniões, prefira horários à tarde após às 14h quando possível, e padrão para durações de 30 minutos a menos que especificado de outra forma\"\n",
    "\n",
    "Isso demonstra a capacidade do sistema de:\n",
    "- Organizar preferências aprendidas em categorias apropriadas\n",
    "- Extrair múltiplas percepções de uma única instância de feedback\n",
    "- Aplicar preferências de reunião tanto em contextos de calendário quanto de email\n",
    "- Capturar nuance com qualificadores apropriados (\"quando possível\", \"a menos que especificado de outra forma\")\n",
    "- Manter a estrutura hierárquica da memória\n",
    "\n",
    "O email resultante mostra todas essas preferências aplicadas: é mais curto, menos formal, inclui uma declaração de encerramento sobre esperar pela conversa, e referencia corretamente o horário de reunião de 30 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usuário aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUPÇÃO:\")\n",
    "        print(f\"Solicitação de Ação: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after feedback\n",
    "print(\"\\nVerificando memória após aceitar write_email após feedback:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e63cb",
   "metadata": {},
   "source": [
    "Olhar o histórico completo de mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_5)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac9df0-cd39-4c32-a073-c2482d9554b6",
   "metadata": {},
   "source": [
    "## Local Deployment\n",
    "\n",
    "You can find this graph with memory integration in the `src/email_assistant` directory:\n",
    "\n",
    "* `src/email_assistant/email_assistant_hitl_memory.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4aa8b0-f8b7-4197-8701-87dda60daa26",
   "metadata": {},
   "source": [
    "Email to test: \n",
    "```\n",
    "{\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}\n",
    "```\n",
    "\n",
    "As before, if you go to [dev.agentinbox.ai](https://dev.agentinbox.ai/), you can easily connect to the graph:\n",
    "\n",
    "   * Graph name: the name from the `langgraph.json` file (`email_assistant_hitl_memory`)\n",
    "   * Graph URL: `http://127.0.0.1:2024/`\n",
    "\n",
    "![inbox](img/agent-inbox-edit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075a3ea",
   "metadata": {},
   "source": [
    "The Memory tab in LangGraph Studio offers a real-time view of how your preferences are being captured and updated with each interaction:\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "Through continued use, the system becomes increasingly personalized:\n",
    "- It learns which emails you want to respond to, be notified about, or ignore\n",
    "- It adapts to your communication style preferences\n",
    "- It remembers your scheduling preferences\n",
    "- It refines its understanding with each interaction\n",
    "\n",
    "This combination of HITL and memory creates a system that balances automation with control - handling routine tasks automatically while learning from your feedback to become more aligned with your preferences over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad7580",
   "metadata": {},
   "source": [
    "## Hosted Deployment with Gmail Tools\n",
    "\n",
    "If you want to actually run this on your own email, you can deploy the graph with Gmail tools. \n",
    "\n",
    "Set up your Gmail credentials [following here](https://github.com/langchain-ai/agents-from-scratch/blob/main/src/email_assistant/tools/gmail/README.md).\n",
    "\n",
    "There is a graph set up with Gmail tools:\n",
    "\n",
    "```shell\n",
    "python src/email_assistant/email_assistant_hitl_memory_gmail.py\n",
    "```\n",
    "\n",
    "[One of the deployment options is `hosted`](https://langchain-ai.github.io/langgraph/tutorials/deployment/#other-deployment-options), and you can simply connect the deployed graph URL to the Agent Inbox as done with the local deployment.\n",
    "\n",
    "## Improving Memory \n",
    "\n",
    "Our current memory schema and updating is extremely simple: \n",
    "\n",
    "* Our schema is a string\n",
    "* We always overwrite the existing memory with a new string\n",
    " \n",
    "The store can be easily [configured for semantic search](https://langchain-ai.github.io/langgraph/cloud/deployment/semantic_search/) over a collection of memories. \n",
    "\n",
    "Also consider using [LangMem](https://langchain-ai.github.io/langmem/) for more advanced memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dbb9b-5c9a-4236-912e-02b3d9f674f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
