{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d047044f",
   "metadata": {},
   "source": [
    "# Agentes com Mem√≥ria\n",
    "\n",
    "Temos um assistente de email que usa um roteador para triagem de emails e ent√£o passa o email para o agente gerar uma resposta. Tamb√©m o avaliamos e adicionamos humano-no-loop (HITL). Mas e se nosso assistente pudesse **aprender** com as intera√ß√µes para melhorar ao longo do tempo? Isso √© onde a **mem√≥ria** entra.\n",
    "\n",
    "![overview-img](img/overview_memory.png)\n",
    "\n",
    "A mem√≥ria no LangGraph opera em dois n√≠veis distintos:\n",
    "\n",
    "**Mem√≥ria Com Escopo de Thread (Curto prazo)** opera dentro dos limites de um √∫nico thread de conversa. √â gerenciada automaticamente como parte do estado do grafo e persistida atrav√©s de checkpoints com escopo de thread. Este tipo de mem√≥ria ret√©m hist√≥rico de conversa, arquivos enviados, documentos recuperados e outros artefatos gerados durante a intera√ß√£o. Pense nisso como a mem√≥ria de trabalho que mant√©m contexto dentro de uma conversa espec√≠fica, permitindo que o agente referencie mensagens ou a√ß√µes anteriores sem come√ßar do zero a cada vez.\n",
    "\n",
    "**Mem√≥ria Atrav√©s de Threads (Longo prazo)** se estende al√©m de conversas individuais, criando uma base de conhecimento persistente que abrange m√∫ltiplas sess√µes. Esta mem√≥ria √© armazenada como documentos JSON em um armazenamento de mem√≥ria, organizada por namespaces (como pastas) e chaves distintas (como nomes de arquivo). Diferente da mem√≥ria com escopo de thread, esta informa√ß√£o persiste mesmo ap√≥s as conversas terminarem, permitindo que o sistema se lembre de prefer√™ncias do usu√°rio, decis√µes passadas e conhecimento acumulado. Isso √© o que permite que um agente verdadeiramente aprenda e se adapte ao longo do tempo, em vez de tratar cada intera√ß√£o como isolada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143094b4",
   "metadata": {},
   "source": [
    "#### Carregar Vari√°veis de Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99855af",
   "metadata": {},
   "source": [
    "## Mem√≥ria no LangGraph\n",
    "\n",
    "### Mem√≥ria Com Escopo de Thread e Atrav√©s de Threads\n",
    "\n",
    "Primeiro, vale a pena explicar como [a mem√≥ria funciona no LangGraph](https://langchain-ai.github.io/langgraph/concepts/memory/). LangGraph oferece dois tipos principais de mem√≥ria:\n",
    "\n",
    "**Mem√≥ria Com Escopo de Thread (Curto prazo)** opera dentro dos limites de um √∫nico thread de conversa. √â gerenciada automaticamente como parte do estado do grafo e persistida atrav√©s de checkpoints com escopo de thread. Este tipo de mem√≥ria ret√©m hist√≥rico de conversa, arquivos enviados, documentos recuperados e outros artefatos gerados durante a intera√ß√£o. Pense nisso como a mem√≥ria de trabalho que mant√©m contexto dentro de uma conversa espec√≠fica, permitindo que o agente referencie mensagens ou a√ß√µes anteriores sem come√ßar do zero a cada vez.\n",
    "\n",
    "**Mem√≥ria Atrav√©s de Threads (Longo prazo)** se estende al√©m de conversas individuais, criando uma base de conhecimento persistente que abrange m√∫ltiplas sess√µes. Esta mem√≥ria √© armazenada como documentos JSON em um armazenamento de mem√≥ria, organizada por namespaces (como pastas) e chaves distintas (como nomes de arquivo). Diferente da mem√≥ria com escopo de thread, esta informa√ß√£o persiste mesmo ap√≥s as conversas terminarem, permitindo que o sistema se lembre de prefer√™ncias do usu√°rio, decis√µes passadas e conhecimento acumulado. Isso √© o que permite que um agente verdadeiramente aprenda e se adapte ao longo do tempo, em vez de tratar cada intera√ß√£o como isolada.\n",
    "\n",
    "Existem diferentes op√ß√µes de armazenamento para mem√≥ria atrav√©s de threads:\n",
    "\n",
    "1. **Na Mem√≥ria (ex. notebooks)**:\n",
    "   - Usa `from langgraph.store.memory import InMemoryStore`\n",
    "   - Simples e r√°pido para testes e desenvolvimento local\n",
    "2. **Desenvolvimento Local com `langgraph dev`**:\n",
    "   - Similar ao InMemoryStore mas com pseudo-persist√™ncia\n",
    "3. **LangGraph Platform ou Deployments de Produ√ß√£o**:\n",
    "   - Para deployments hospedados, voc√™ tem acesso a um armazenamento de produ√ß√£o\n",
    "\n",
    "Vamos usar o `InMemoryStore` aqui no notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb204c",
   "metadata": {},
   "source": [
    "As mem√≥rias s√£o organizadas por namespace usando uma tupla, que neste exemplo espec√≠fico ser√° (`<user_id>`, \"memories\"). O namespace pode ter qualquer comprimento e representar qualquer coisa, n√£o precisa ser espec√≠fico do usu√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0488a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8b303",
   "metadata": {},
   "source": [
    "Usamos o m√©todo `store.put` para salvar mem√≥rias em nosso namespace no armazenamento. Quando fazemos isso, especificamos o namespace, como definido acima, e um par chave-valor para a mem√≥ria: a chave √© simplesmente um identificador √∫nico para a mem√≥ria (memory_id) e o valor (um dicion√°rio) √© a pr√≥pria mem√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af95b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60408492",
   "metadata": {},
   "source": [
    "Podemos ler as mem√≥rias em nosso namespace usando o m√©todo `store.search`, que retornar√° todas as mem√≥rias para um usu√°rio espec√≠fico como uma lista. A mem√≥ria mais recente √© a √∫ltima da lista. Cada tipo de mem√≥ria √© uma classe Python (`Item`) com certos atributos. Podemos acess√°-la como um dicion√°rio convertendo via `.dict`. Os atributos que possui s√£o mostrados abaixo, mas o mais importante geralmente √© `value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "memories[-1].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3e781",
   "metadata": {},
   "source": [
    "Para usar isso em um grafo, tudo que precisamos fazer √© compilar o grafo com o store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need this because we want to enable threads (conversations)\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "checkpointer = InMemorySaver()\n",
    "# We need this because we want to enable across-thread memory\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()\n",
    "# Compile the graph with the checkpointer and store\n",
    "# graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982928",
   "metadata": {},
   "source": [
    "Vamos pegar nosso grafo com HITL e adicionar mem√≥ria a ele. Isso ser√° muito similar ao que t√≠nhamos anteriormente. Simplesmente atualizaremos a mem√≥ria no store quando recebermos feedback do usu√°rio.\n",
    "\n",
    "A principal diferen√ßa ser√° adicionar um [LangGraph Store](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory) para persistir as mem√≥rias.\n",
    "\n",
    "## Mem√≥ria\n",
    "\n",
    "Vamos implementar mem√≥ria que captura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38308fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, agent_system_prompt_hitl_memory, default_triage_instructions, default_background, default_response_preferences, default_cal_preferences, MEMORY_UPDATE_INSTRUCTIONS, MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT\n",
    "from email_assistant.tools.default.prompt_templates import HITL_MEMORY_TOOLS_PROMPT\n",
    "from email_assistant.schemas import State, RouterSchema, StateInput\n",
    "from email_assistant.utils import parse_email, format_for_display, format_email_markdown\n",
    "\n",
    "# Agent tools\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "class Question(BaseModel):\n",
    "      \"\"\"Question to ask user.\"\"\"\n",
    "      content: str\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool\n",
    "\n",
    "# All tools available to the agent\n",
    "tools = [\n",
    "    write_email,\n",
    "    schedule_meeting,\n",
    "    check_calendar_availability,\n",
    "    Question,\n",
    "    Done\n",
    "]\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema)\n",
    "\n",
    "# Initialize the LLM, enforcing tool use (of any available tools) for agent\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03538f56",
   "metadata": {},
   "source": [
    "Agora, esta √© a parte cr√≠tica! Atualmente n√£o capturamos nenhum feedback do usu√°rio em nosso grafo.\n",
    "\n",
    "### Gerenciamento de Mem√≥ria\n",
    "\n",
    "O que *queremos* fazer √© bastante direto: queremos adicionar o feedback ao `Store` de mem√≥ria. Se compilarmos nosso grafo com o `Store`, podemos acess√°-lo em qualquer n√≥. Ent√£o vamos modificar o `interrupt_handler` para salvar o feedback do usu√°rio no `Store`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2715152-2d19-4449-be4b-fdc602eee52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(default_triage_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ab99d-bc21-4cf7-a58a-261e82920566",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_cal_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd98f1-15a7-4fbb-8cce-cbbb0503d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(default_response_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(store, namespace, default_content=None):\n",
    "    \"\"\"Get memory from the store or initialize with default if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        store: LangGraph BaseStore instance to search for existing memory\n",
    "        namespace: Tuple defining the memory namespace, e.g. (\"email_assistant\", \"triage_preferences\")\n",
    "        default_content: Default content to use if memory doesn't exist\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the memory profile, either from existing memory or the default\n",
    "    \"\"\"\n",
    "    # Search for existing memory with namespace and key\n",
    "    user_preferences = store.get(namespace, \"user_preferences\")\n",
    "\n",
    "    # If memory exists, return its content (the value)\n",
    "    if user_preferences:\n",
    "        return user_preferences.value\n",
    "\n",
    "    # If memory doesn't exist, add it to the store and return the default content\n",
    "    else:\n",
    "        # Namespace, key, value\n",
    "        store.put(namespace, \"user_preferences\", default_content)\n",
    "        user_preferences = default_content\n",
    "\n",
    "    # Return the default content\n",
    "    return user_preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5181e6",
   "metadata": {},
   "source": [
    "Para 2) atualizar mem√≥ria, podemos usar alguns truques do [guia de prompting GPT-4.1](https://cookbook.openai.com/examples/gpt4-1_prompting_guide) para nos ajudar a atualizar a mem√≥ria:\n",
    "\n",
    "1. **Instru√ß√µes detalhadas**: Fornecer instru√ß√µes espec√≠ficas sobre como atualizar prefer√™ncias\n",
    "2. **Exemplos**: Mostrar exemplos de atualiza√ß√µes de mem√≥ria bem formatadas  \n",
    "3. **Refor√ßo**: Usar lembretes para garantir que as instru√ß√µes sejam seguidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Markdown(MEMORY_UPDATE_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8aa70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPreferences(BaseModel):\n",
    "    \"\"\"Updated user preferences based on user's feedback.\"\"\"\n",
    "    chain_of_thought: str = Field(description=\"Reasoning about which user preferences need to add / update if required\")\n",
    "    user_preferences: str = Field(description=\"Updated user preferences\")\n",
    "\n",
    "def update_memory(store, namespace, messages):\n",
    "    \"\"\"Update memory profile in the store.\n",
    "\n",
    "    Args:\n",
    "        store: LangGraph BaseStore instance to update memory\n",
    "        namespace: Tuple defining the memory namespace, e.g. (\"email_assistant\", \"triage_preferences\")\n",
    "        messages: List of messages to update the memory with\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the existing memory\n",
    "    user_preferences = store.get(namespace, \"user_preferences\")\n",
    "\n",
    "    # Update the memory\n",
    "    llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google-genai\", temperature=0.0).with_structured_output(UserPreferences)\n",
    "    result = llm.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": MEMORY_UPDATE_INSTRUCTIONS.format(current_profile=user_preferences.value, namespace=namespace)},\n",
    "        ] + messages\n",
    "    )\n",
    "\n",
    "    # Save the updated memory to the store\n",
    "    store.put(namespace, \"user_preferences\", result.user_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af20960",
   "metadata": {},
   "source": [
    "Configuramos o roteador de triagem como t√≠nhamos antes, com uma pequena mudan√ßa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a789ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_router(state: State, store: BaseStore) -> Command[Literal[\"triage_interrupt_handler\", \"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\n",
    "\n",
    "    The triage step prevents the assistant from wasting time on:\n",
    "    - Marketing emails and spam\n",
    "    - Company-wide announcements\n",
    "    - Messages meant for other teams\n",
    "    \"\"\"\n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification\n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Search for existing triage_preferences memory\n",
    "    triage_instructions = get_memory(store, (\"email_assistant\", \"triage_preferences\"), default_triage_instructions)\n",
    "\n",
    "    # Format system prompt with background and triage instructions\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=triage_instructions,\n",
    "    )\n",
    "\n",
    "    # Run the router LLM\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Decision\n",
    "    classification = result.classification\n",
    "\n",
    "    # Process the classification decision\n",
    "    if classification == \"respond\":\n",
    "        print(\"üìß Classifica√ß√£o: RESPONDER - Este email requer uma resposta\")\n",
    "        # Next node\n",
    "        goto = \"response_agent\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": result.classification,\n",
    "            \"messages\": [{\"role\": \"user\",\n",
    "                            \"content\": f\"Respond to the email: {email_markdown}\"\n",
    "                        }],\n",
    "        }\n",
    "\n",
    "    elif classification == \"ignore\":\n",
    "        print(\"üö´ Classifica√ß√£o: IGNORAR - Este email pode ser ignorado\")\n",
    "\n",
    "        # Next node\n",
    "        goto = END\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    elif classification == \"notify\":\n",
    "        print(\"üîî Classifica√ß√£o: NOTIFICAR - Este email cont√©m informa√ß√µes importantes\")\n",
    "\n",
    "        # Next node\n",
    "        goto = \"triage_interrupt_handler\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {classification}\")\n",
    "\n",
    "    return Command(goto=goto, update=update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be4d63",
   "metadata": {},
   "source": [
    "Precisamos apenas fazer uma pequena altera√ß√£o no manipulador de interrup√ß√£o para atualizar a mem√≥ria quando o usu√°rio fornecer feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ef46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_interrupt_handler(state: State, store: BaseStore) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Handles interrupts from the triage step\"\"\"\n",
    "\n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification\n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Create messages\n",
    "    messages = [{\"role\": \"user\",\n",
    "                \"content\": f\"Email to notify user about: {email_markdown}\"\n",
    "                }]\n",
    "\n",
    "    # Create interrupt for Agent Inbox\n",
    "    request = {\n",
    "        \"action_request\": {\n",
    "            \"action\": f\"Email Assistant: {state['classification_decision']}\",\n",
    "            \"args\": {}\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"allow_ignore\": True,\n",
    "            \"allow_respond\": True,\n",
    "            \"allow_edit\": False,\n",
    "            \"allow_accept\": False,\n",
    "        },\n",
    "        # Email to show in Agent Inbox\n",
    "        \"description\": email_markdown,\n",
    "    }\n",
    "\n",
    "    # Send to Agent Inbox and wait for response\n",
    "    response = interrupt([request])[0]\n",
    "\n",
    "    # If user provides feedback, go to response agent and use feedback to respond to email\n",
    "    if response[\"type\"] == \"response\":\n",
    "        # Add feedback to messages\n",
    "        user_input = response[\"args\"]\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"User wants to reply to the email. Use this feedback to respond: {user_input}\"\n",
    "                        })\n",
    "        # This is new: update triage_preferences with feedback\n",
    "        update_memory(store, (\"email_assistant\", \"triage_preferences\"), [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The user decided to respond to the email, so update the triage preferences to capture this.\"\n",
    "        }] + messages)\n",
    "\n",
    "        goto = \"response_agent\"\n",
    "\n",
    "    # If user ignores email, go to END\n",
    "    elif response[\"type\"] == \"ignore\":\n",
    "        # Make note of the user's decision to ignore the email\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"The user decided to ignore the email even though it was classified as notify. Update triage preferences to capture this.\"\n",
    "                        })\n",
    "        # This is new: triage_preferences with feedback\n",
    "        update_memory(store, (\"email_assistant\", \"triage_preferences\"), messages)\n",
    "        goto = END\n",
    "\n",
    "    # Catch all other responses\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid response: {response}\")\n",
    "\n",
    "    # Update the state\n",
    "    update = {\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd428f5",
   "metadata": {},
   "source": [
    "Agora que temos os gerenciadores de mem√≥ria configurados, podemos usar as prefer√™ncias armazenadas ao gerar respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: State, store: BaseStore):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    # Search for existing cal_preferences memory\n",
    "    cal_preferences = get_memory(store, (\"email_assistant\", \"cal_preferences\"), default_cal_preferences)\n",
    "\n",
    "    # Search for existing response_preferences memory\n",
    "    response_preferences = get_memory(store, (\"email_assistant\", \"response_preferences\"), default_response_preferences)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt_hitl_memory.format(tools_prompt=HITL_MEMORY_TOOLS_PROMPT,\n",
    "                                                                                         background=default_background,\n",
    "                                                                                         response_preferences=response_preferences,\n",
    "                                                                                         cal_preferences=cal_preferences)}\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60aff5d",
   "metadata": {},
   "source": [
    "### Integra√ß√£o de Mem√≥ria no Manipulador de Interrup√ß√£o\n",
    "\n",
    "Da mesma forma, adicionaremos mem√≥ria ao manipulador de interrup√ß√£o!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrupt_handler(state: State, store: BaseStore) -> Command[Literal[\"llm_call\", \"__end__\"]]:\n",
    "    \"\"\"Creates an interrupt for human review of tool calls\"\"\"\n",
    "\n",
    "    # Store messages\n",
    "    result = []\n",
    "\n",
    "    # Go to the LLM call node next\n",
    "    goto = \"llm_call\"\n",
    "\n",
    "    # Iterate over the tool calls in the last message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "\n",
    "        # Allowed tools for HITL\n",
    "        hitl_tools = [\"write_email\", \"schedule_meeting\", \"Question\"]\n",
    "\n",
    "        # If tool is not in our HITL list, execute it directly without interruption\n",
    "        if tool_call[\"name\"] not in hitl_tools:\n",
    "\n",
    "            # Execute tool without interruption\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "            continue\n",
    "\n",
    "        # Get original email from email_input in state\n",
    "        email_input = state[\"email_input\"]\n",
    "        author, to, subject, email_thread = parse_email(email_input)\n",
    "        original_email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "        # Format tool call for display and prepend the original email\n",
    "        tool_display = format_for_display(tool_call)\n",
    "        description = original_email_markdown + tool_display\n",
    "\n",
    "        # Configure what actions are allowed in Agent Inbox\n",
    "        if tool_call[\"name\"] == \"write_email\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"Question\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": False,\n",
    "                \"allow_accept\": False,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Create the interrupt request\n",
    "        request = {\n",
    "            \"action_request\": {\n",
    "                \"action\": tool_call[\"name\"],\n",
    "                \"args\": tool_call[\"args\"]\n",
    "            },\n",
    "            \"config\": config,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "        # Send to Agent Inbox and wait for response\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        # Handle the responses\n",
    "        if response[\"type\"] == \"accept\":\n",
    "\n",
    "            # Execute the tool with original args\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "\n",
    "        elif response[\"type\"] == \"edit\":\n",
    "\n",
    "            # Tool selection\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            initial_tool_call = tool_call[\"args\"]\n",
    "\n",
    "            # Get edited args from Agent Inbox\n",
    "            edited_args = response[\"args\"][\"args\"]\n",
    "\n",
    "            # Update the AI message's tool call with edited content (reference to the message in the state)\n",
    "            ai_message = state[\"messages\"][-1] # Get the most recent message from the state\n",
    "            current_id = tool_call[\"id\"] # Store the ID of the tool call being edited\n",
    "\n",
    "            # Create a new list of tool calls by filtering out the one being edited and adding the updated version\n",
    "            # This avoids modifying the original list directly (immutable approach)\n",
    "            updated_tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "            ]\n",
    "\n",
    "            # Create a new copy of the message with updated tool calls rather than modifying the original\n",
    "            # This ensures state immutability and prevents side effects in other parts of the code\n",
    "            # When we update the messages state key (\"messages\": result), the add_messages reducer will\n",
    "            # overwrite existing messages by id and we take advantage of this here to update the tool calls.\n",
    "            result.append(ai_message.model_copy(update={\"tool_calls\": updated_tool_calls}))\n",
    "\n",
    "            # Save feedback in memory and update the write_email tool call with the edited content from Agent Inbox\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "\n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "\n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"response_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User edited the email response. Here is the initial email generated by the assistant: {initial_tool_call}. Here is the edited email: {edited_args}. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            # Save feedback in memory and update the schedule_meeting tool call with the edited content from Agent Inbox\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "\n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "\n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"cal_preferences\"), [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User edited the calendar invitation. Here is the initial calendar invitation generated by the assistant: {initial_tool_call}. Here is the edited calendar invitation: {edited_args}. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            # Catch all other tool calls\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"ignore\":\n",
    "\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this email draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the email draft. That means they did not want to respond to the email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this calendar meeting draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the calendar meeting draft. That means they did not want to schedule a meeting for this email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this question. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"triage_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The user ignored the Question. That means they did not want to answer the question or deal with this email. Update the triage preferences to ensure emails of this type are not classified as respond. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"response\":\n",
    "            # User provided feedback\n",
    "            user_feedback = response[\"args\"]\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the email. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"response_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User gave feedback, which we can use to update the response preferences. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the meeting request. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # This is new: update the memory\n",
    "                update_memory(store, (\"email_assistant\", \"cal_preferences\"), state[\"messages\"] + result + [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"User gave feedback, which we can use to update the calendar preferences. Follow all instructions above, and remember: {MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT}.\"\n",
    "                }])\n",
    "\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User answered the question, which can we can use for any follow up actions. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "    # Update the state\n",
    "    update = {\n",
    "        \"messages\": result,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedcaec",
   "metadata": {},
   "source": [
    "O resto √© igual ao anterior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.utils import show_graph\n",
    "\n",
    "# Conditional edge function\n",
    "def should_continue(state: State, store: BaseStore) -> Literal[\"interrupt_handler\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"interrupt_handler\"\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes - with store parameter\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"interrupt_handler\", interrupt_handler)\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"interrupt_handler\": \"interrupt_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the agent\n",
    "response_agent = agent_builder.compile()\n",
    "\n",
    "# Build overall workflow with store and checkpointer\n",
    "overall_workflow = (\n",
    "    StateGraph(State, input=StateInput)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(triage_interrupt_handler)\n",
    "    .add_node(\"response_agent\", response_agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ")\n",
    "\n",
    "email_assistant = overall_workflow.compile()\n",
    "show_graph(email_assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43747219",
   "metadata": {},
   "source": [
    "## Testando o agente com mem√≥ria\n",
    "\n",
    "Agora que implementamos mem√≥ria em nosso assistente de email, vamos testar como o sistema aprende com o feedback do usu√°rio e se adapta ao longo do tempo. Esta se√ß√£o de testes explora como diferentes tipos de intera√ß√µes do usu√°rio criam atualiza√ß√µes de mem√≥ria distintas que melhoram o desempenho futuro do assistente.\n",
    "\n",
    "As principais quest√µes que estamos respondendo atrav√©s destes testes:\n",
    "1. Como o sistema captura e armazena as prefer√™ncias do usu√°rio?\n",
    "2. Como essas prefer√™ncias armazenadas afetam decis√µes futuras?\n",
    "3. Quais padr√µes de intera√ß√£o levam a que tipos de atualiza√ß√µes de mem√≥ria?\n",
    "\n",
    "Primeiro, vamos construir uma fun√ß√£o auxiliar para exibir o conte√∫do da mem√≥ria para que possamos acompanhar como ela evolui ao longo de nossos testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59079929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Helper function to display memory content\n",
    "def display_memory_content(store, namespace=None):\n",
    "    # Display current memory content for all namespaces\n",
    "    print(\"\\n======= CURRENT MEMORY CONTENT =======\")\n",
    "    if namespace:\n",
    "        memory = store.get(namespace, \"user_preferences\")\n",
    "        if memory:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print(memory.value)\n",
    "        else:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print(\"Nenhuma mem√≥ria encontrada\")\n",
    "    else:\n",
    "        for namespace in [\n",
    "            (\"email_assistant\", \"triage_preferences\"),\n",
    "            (\"email_assistant\", \"response_preferences\"),\n",
    "            (\"email_assistant\", \"cal_preferences\"),\n",
    "            (\"email_assistant\", \"background\")\n",
    "        ]:\n",
    "            memory = store.get(namespace, \"user_preferences\")\n",
    "            if memory:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print(memory.value)\n",
    "            else:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print(\"Nenhuma mem√≥ria encontrada\")\n",
    "            print(\"=======================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397114bf",
   "metadata": {},
   "source": [
    "### Aceitar `write_email` e `schedule_meeting`\n",
    "\n",
    "Nosso primeiro teste examina o que acontece quando um usu√°rio aceita as a√ß√µes do agente sem modifica√ß√£o. Este caso base nos ajuda a entender como o sistema se comporta quando nenhum feedback √© fornecido:\n",
    "\n",
    "1. Usaremos o mesmo email de planejamento tribut√°rio de nossos testes anteriores\n",
    "2. O sistema o classificar√° como \"RESPOND\" e propor√° agendar uma reuni√£o\n",
    "3. Aceitaremos o agendamento da reuni√£o sem mudan√ßas\n",
    "4. O agente gerar√° um email confirmando a reuni√£o\n",
    "5. Aceitaremos o email sem mudan√ßas\n",
    "\n",
    "Este teste demonstra o comportamento padr√£o de nosso sistema habilitado para mem√≥ria. Quando um usu√°rio simplesmente aceita a√ß√µes propostas, esperamos atualiza√ß√µes m√≠nimas ou nenhuma atualiza√ß√£o de mem√≥ria, j√° que n√£o h√° feedback expl√≠cito do qual aprender. No entanto, o sistema ainda utilizar√° a mem√≥ria existente (se houver) ao gerar suas respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649cee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "# Email will be classified as \"respond\"\n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Executando o grafo at√© a primeira interrup√ß√£o...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e199e",
   "metadata": {},
   "source": [
    "Aceitar a chamada de ferramenta `schedule_meeting`\n",
    "\n",
    "Ao examinarmos a proposta inicial de `schedule_meeting`, observe como o sistema usa a mem√≥ria existente para informar suas decis√µes:\n",
    "\n",
    "1. As prefer√™ncias padr√£o de calend√°rio mostram uma prefer√™ncia por reuni√µes de 30 minutos, embora o email solicite 45 minutos\n",
    "2. O agente ainda prop√µe uma reuni√£o de 45 minutos, respeitando a solicita√ß√£o espec√≠fica do remetente\n",
    "3. Aceitamos esta proposta sem modifica√ß√£o para ver se a simples aceita√ß√£o desencadeia alguma atualiza√ß√£o de mem√≥ria\n",
    "\n",
    "Ap√≥s executar este passo, verificaremos o conte√∫do da mem√≥ria para confirmar se a aceita√ß√£o sozinha leva a atualiza√ß√µes de mem√≥ria. A simples aceita√ß√£o representa a experi√™ncia base do usu√°rio - o sistema funciona conforme pretendido sem exigir ajustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usu√°rio aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b80f99",
   "metadata": {},
   "source": [
    "Aceitar a chamada de ferramenta `write_email`\n",
    "\n",
    "Agora aceitaremos o rascunho de email que confirma o agendamento da reuni√£o:\n",
    "\n",
    "1. O rascunho de email √© gerado com conhecimento de nossas prefer√™ncias de calend√°rio\n",
    "2. Ele inclui detalhes sobre o hor√°rio da reuni√£o, dura√ß√£o e prop√≥sito\n",
    "3. Aceitaremos sem mudan√ßas para completar o caso de teste base\n",
    "\n",
    "Ap√≥s aceitar, verificaremos todos os armazenamentos de mem√≥ria para ver se ocorreram atualiza√ß√µes. Como esperado, simplesmente aceitar as propostas do agente n√£o fornece sinais de aprendizado fortes - n√£o h√° feedback claro sobre o que o usu√°rio gosta ou n√£o gosta da abordagem do agente.\n",
    "\n",
    "O link de rastreamento mostra a execu√ß√£o completa do fluxo de trabalho, onde podemos ver que a mem√≥ria √© usada na chamada LLM para gera√ß√£o de resposta, mas nenhuma atualiza√ß√£o de mem√≥ria ocorre, que √© o comportamento esperado para simples aceita√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12035cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usu√°rio aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting the write_email tool call\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc178d",
   "metadata": {},
   "source": [
    "Podemos olhar as mensagens completas e o rastreamento: \n",
    "\n",
    "https://smith.langchain.com/public/86ff6474-29fe-452e-8829-b05a91b458eb/r\n",
    "\n",
    "Voc√™ notar√° que a mem√≥ria √© usada na chamada LLM para responder. \n",
    "\n",
    "Mas o armazenamento de mem√≥ria *n√£o* √© atualizado, porque n√£o adicionamos nenhum feedback via HITL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58201a21",
   "metadata": {},
   "source": [
    "### Editar `write_email` e `schedule_meeting`\n",
    "\n",
    "Este teste explora como o sistema aprende a partir de edi√ß√µes diretas √†s suas a√ß√µes propostas. Quando usu√°rios modificam as sugest√µes do agente, isso cria sinais de aprendizado claros e espec√≠ficos sobre suas prefer√™ncias:\n",
    "\n",
    "1. Usaremos o mesmo email de planejamento tribut√°rio de antes\n",
    "2. Quando o agente propor uma reuni√£o de 45 minutos, editaremos para:\n",
    "   - Mudar a dura√ß√£o para 30 minutos (correspondendo √† nossa prefer√™ncia armazenada)\n",
    "   - Tornar o assunto mais conciso\n",
    "3. Quando o agente rascunhar um email, editaremos para ser:\n",
    "   - Mais curto e menos formal\n",
    "   - Estruturado de forma diferente\n",
    "\n",
    "Edi√ß√µes fornecem o feedback mais expl√≠cito sobre prefer√™ncias do usu√°rio, permitindo que o sistema aprenda exatamente quais mudan√ßas s√£o desejadas. Esperamos ver atualiza√ß√µes espec√≠ficas e direcionadas em nossos armazenamentos de mem√≥ria que reflitam essas edi√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same email as before\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_2 = uuid.uuid4()\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# Run the graph until the first interrupt - will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "print(\"Executando o grafo at√© a primeira interrup√ß√£o...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_2):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73ba71",
   "metadata": {},
   "source": [
    "Editar a chamada da ferramenta `schedule_meeting`\n",
    "\n",
    "Quando editamos a proposta de reuni√£o, estamos fornecendo feedback direto e expl√≠cito sobre nossas prefer√™ncias. Isso cria uma oportunidade significativa de aprendizado para o sistema:\n",
    "\n",
    "1. O agente inicialmente prop√µe uma reuni√£o de 45 minutos (a dura√ß√£o solicitada no email)\n",
    "2. N√≥s editamos para 30 minutos e simplificamos o assunto de \"Tax Planning Strategies Discussion\" para \"Tax Planning Discussion\"\n",
    "3. Isso cria feedback claro e espec√≠fico sobre nossas prefer√™ncias de tempo e conven√ß√µes de nomenclatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af760977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the schedule_meeting tool call\n",
    "print(\"\\nSimulando usu√°rio editando a schedule_meeting chamada de ferramenta...\")\n",
    "edited_schedule_args = {\n",
    "    \"attendees\": [\"pm@client.com\", \"lance@company.com\"],\n",
    "    \"subject\": \"Tax Planning Discussion\",\n",
    "    \"duration_minutes\": 30, # Changed from 45 to 30\n",
    "    \"preferred_day\": \"2025-04-22\",\n",
    "    \"start_time\": 14\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_schedule_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing schedule_meeting\n",
    "print(\"\\nVerificando mem√≥ria ap√≥s editar schedule_meeting:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb324f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "{'preferences': '\\n30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n'}\n",
    "```\n",
    "\n",
    "```\n",
    "{'preferences': \"30 minute meetings are preferred, but 15 minute meetings are also acceptable.\\n\\nUser prefers 30 minute meetings over longer durations such as 45 minutes. When scheduling, default to 30 minutes unless otherwise specified. Subject lines should be concise (e.g., 'Tax Planning Discussion' instead of 'Tax Planning Strategies Discussion').\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc585a",
   "metadata": {},
   "source": [
    "Olhando para a mem√≥ria ap√≥s editar o convite de calend√°rio, podemos ver que ela foi atualizada:\n",
    "\n",
    "1. O sistema identificou que preferimos reuni√µes de 30 minutos em vez de dura√ß√µes mais longas\n",
    "2. Tamb√©m capturou nossa prefer√™ncia por assuntos de reuni√£o concisos\n",
    "\n",
    "O que √© particularmente impressionante sobre esta atualiza√ß√£o de mem√≥ria √©:\n",
    "- Ela n√£o apenas registra nossa edi√ß√£o espec√≠fica, mas generaliza para um padr√£o de prefer√™ncia mais amplo\n",
    "- Preserva todo o conte√∫do de mem√≥ria existente enquanto adiciona a nova informa√ß√£o\n",
    "- Extrai m√∫ltiplos sinais de prefer√™ncia de uma √∫nica intera√ß√£o de edi√ß√£o\n",
    "\n",
    "Agora, vamos editar o rascunho de email para ver como o sistema captura diferentes tipos de prefer√™ncias de comunica√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))\n",
    "# Now simulate user editing the write_email tool call\n",
    "print(\"\\nSimulando usu√°rio editando a write_email chamada de ferramenta...\")\n",
    "edited_email_args = {\n",
    "    \"to\": \"pm@client.com\",\n",
    "    \"subject\": \"Re: Tax season let's schedule call\",\n",
    "    \"content\": \"Thanks! I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\\n\\nBest regards,\\nLance Martin\"\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_email_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing write_email\n",
    "print(\"\\nVerificando mem√≥ria ap√≥s editar write_email:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbd5f9",
   "metadata": {},
   "source": [
    "Nossa edi√ß√£o de email revela capacidades de aprendizado ainda mais sofisticadas:\n",
    "\n",
    "1. Encurtamos e simplificamos drasticamente o conte√∫do do email\n",
    "2. Mudamos o tom para ser mais casual\n",
    "3. Adicionamos uma pergunta pedindo confirma√ß√£o em vez de assumir que o hor√°rio funciona\n",
    "4. Alteramos ligeiramente os detalhes da reuni√£o (dia e hor√°rio)\n",
    "\n",
    "Olhando para a mem√≥ria atualizada, podemos ver que o sistema extraiu uma percep√ß√£o chave sobre nosso estilo de comunica√ß√£o:\n",
    "\n",
    "```\n",
    "Ao agendar uma reuni√£o, pe√ßa ao destinat√°rio para confirmar se o hor√°rio proposto funciona para eles, em vez de assumir e declarar que a reuni√£o j√° est√° agendada.\n",
    "```\n",
    "\n",
    "Isso demonstra a capacidade do sistema de:\n",
    "- Analisar nossa edi√ß√£o n√£o apenas em um n√≠vel superficial, mas para entender a inten√ß√£o\n",
    "- Extrair princ√≠pios generaliz√°veis de exemplos espec√≠ficos\n",
    "- Preservar toda a orienta√ß√£o existente enquanto adiciona novas percep√ß√µes\n",
    "- Manter a organiza√ß√£o e estrutura da mem√≥ria\n",
    "\n",
    "Essas atualiza√ß√µes de mem√≥ria direcionadas e de alta qualidade melhorar√£o todas as intera√ß√µes futuras sem exigir corre√ß√µes repetidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_2)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d92a42b",
   "metadata": {},
   "source": [
    "### Responder (com feedback) `write_email` e `schedule_meeting`\n",
    "\n",
    "Nosso conjunto final de testes explora o padr√£o de feedback \"resposta\" - fornecendo orienta√ß√£o sem editar ou aceitar diretamente. Este mecanismo de feedback conversacional oferece um meio-termo entre aceita√ß√£o e edi√ß√£o:\n",
    "\n",
    "1. Primeiro, testaremos feedback para agendamento de reuni√£o solicitando:\n",
    "   - Dura√ß√£o mais curta (30 minutos em vez de 45)\n",
    "   - Hor√°rios de reuni√£o √† tarde (ap√≥s √†s 14h)\n",
    "   \n",
    "2. Em seguida, testaremos feedback para rascunho de email solicitando:\n",
    "   - Linguagem mais curta e menos formal\n",
    "   - Uma declara√ß√£o de encerramento espec√≠fica sobre esperar pela reuni√£o\n",
    "   \n",
    "3. Finalmente, testaremos feedback para perguntas fornecendo:\n",
    "   - Uma resposta direta com contexto adicional\n",
    "   - Prefer√™ncias espec√≠ficas (local de brunch, hor√°rio)\n",
    "\n",
    "Esta abordagem de feedback em linguagem natural permite que usu√°rios orientem o assistente sem ter que fazer o trabalho eles mesmos. Esperamos ver atualiza√ß√µes detalhadas de mem√≥ria que extraiam os princ√≠pios gerais de nosso feedback espec√≠fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07676231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_5 = uuid.uuid4()\n",
    "thread_config_5 = {\"configurable\": {\"thread_id\": thread_id_5}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "# Email will be classified as \"respond\"\n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Executando o grafo at√© a primeira interrup√ß√£o...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store, (\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fc45d",
   "metadata": {},
   "source": [
    "Fornecer feedback para a chamada de ferramenta `schedule_meeting`\n",
    "\n",
    "Em vez de editar diretamente a proposta de reuni√£o ou simplesmente aceit√°-la, forneceremos feedback em linguagem natural:\n",
    "\n",
    "1. Solicitamos uma reuni√£o de 30 minutos em vez de 45 minutos\n",
    "2. Expressamos uma prefer√™ncia por reuni√µes √† tarde ap√≥s √†s 14h\n",
    "3. O sistema deve interpretar este feedback e gerar uma nova proposta\n",
    "\n",
    "Esta abordagem conversacional √© frequentemente mais natural e eficiente do que edi√ß√£o direta, especialmente para usu√°rios m√≥veis ou aqueles que preferem dar dire√ß√£o de alto n√≠vel em vez de edi√ß√µes detalhadas.\n",
    "\n",
    "Ap√≥s fornecer feedback, examinaremos a mem√≥ria de prefer√™ncias de calend√°rio para ver como esta orienta√ß√£o em linguagem natural √© capturada. Esperamos ver o sistema extrair tanto a dura√ß√£o da reuni√£o quanto as prefer√™ncias de hor√°rio do dia como princ√≠pios gerais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a151f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usu√°rio fornecendo feedback para a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for schedule_meeting\n",
    "print(\"\\nVerificando mem√≥ria ap√≥s fornecer feedback para schedule_meeting:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088757c",
   "metadata": {},
   "source": [
    "Nossa verifica√ß√£o de mem√≥ria ap√≥s fornecer feedback mostra uma atualiza√ß√£o elegantemente simples de prefer√™ncia de calend√°rio:\n",
    "\n",
    "```\n",
    "Reuni√µes de 30 minutos s√£o preferidas, mas reuni√µes de 15 minutos tamb√©m s√£o aceit√°veis.\n",
    "Reuni√µes √† tarde ap√≥s √†s 14h s√£o preferidas.\n",
    "```\n",
    "\n",
    "O sistema:\n",
    "1. Capturou ambos os aspectos do nosso feedback (dura√ß√£o e hor√°rio do dia)\n",
    "2. Preservou a prefer√™ncia existente sobre reuni√µes de 15 minutos\n",
    "3. Adicionou nossa prefer√™ncia por reuni√µes √† tarde ap√≥s √†s 14h como uma nova linha\n",
    "4. Manteve o formato limpo e leg√≠vel\n",
    "\n",
    "Este mecanismo de feedback em linguagem natural cria a mesma qualidade de atualiza√ß√µes de mem√≥ria que a edi√ß√£o direta, mas requer menos esfor√ßo do usu√°rio. O sistema √© capaz de extrair prefer√™ncias estruturadas de feedback n√£o estruturado, mostrando sua capacidade de aprender a partir de intera√ß√µes conversacionais.\n",
    "\n",
    "Vamos aceitar esta proposta de reuni√£o revisada e passar para o rascunho de email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545063be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usu√°rio aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting schedule_meeting after feedback\n",
    "print(\"\\nVerificando mem√≥ria ap√≥s aceitar schedule_meeting ap√≥s feedback:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ede94",
   "metadata": {},
   "source": [
    "Agora fornecer feedback para a chamada de ferramenta `write_email`\n",
    "\n",
    "Similar ao nosso feedback de reuni√£o, agora forneceremos orienta√ß√£o em linguagem natural para o rascunho de email:\n",
    "\n",
    "1. Solicitamos linguagem \"mais curta e menos formal\" - uma prefer√™ncia de estilo\n",
    "2. Pedimos uma declara√ß√£o de encerramento espec√≠fica sobre esperar pela reuni√£o\n",
    "3. O sistema deve interpretar esta orienta√ß√£o e reescrever o email adequadamente\n",
    "\n",
    "Ap√≥s fornecer este feedback, verificaremos a mem√≥ria de prefer√™ncias de resposta para ver como essas prefer√™ncias de estilo e estrutura s√£o capturadas. Esperamos ver diretrizes generaliz√°veis sobre brevidade, formalidade e declara√ß√µes de encerramento adicionadas ao nosso perfil de prefer√™ncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usu√°rio fornecendo feedback para a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"}]), config=thread_config_5):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for write_email\n",
    "print(\"\\nVerificando mem√≥ria ap√≥s fornecer feedback para write_email:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b360a2",
   "metadata": {},
   "source": [
    "A atualiza√ß√£o de mem√≥ria ap√≥s nosso feedback de email mostra aprendizado altamente sofisticado sobre prefer√™ncias tanto de agendamento de reuni√£o quanto de escrita de email:\n",
    "\n",
    "1. O sistema adicionou uma se√ß√£o completamente nova √†s prefer√™ncias de resposta intitulada \"Ao escrever respostas de email\" com duas prefer√™ncias principais:\n",
    "   - \"Favore√ßa linguagem mais curta e menos formal quando poss√≠vel, a menos que o contexto exija formalidade\"\n",
    "   - \"Inclua uma declara√ß√£o de encerramento expressando que voc√™ espera pela reuni√£o ou conversa ao confirmar compromissos\"\n",
    "\n",
    "2. Tamb√©m adicionou um novo ponto √† se√ß√£o \"Ao responder a solicita√ß√µes de agendamento de reuni√£o\":\n",
    "   - \"Ao agendar reuni√µes, prefira hor√°rios √† tarde ap√≥s √†s 14h quando poss√≠vel, e padr√£o para dura√ß√µes de 30 minutos a menos que especificado de outra forma\"\n",
    "\n",
    "Isso demonstra a capacidade do sistema de:\n",
    "- Organizar prefer√™ncias aprendidas em categorias apropriadas\n",
    "- Extrair m√∫ltiplas percep√ß√µes de uma √∫nica inst√¢ncia de feedback\n",
    "- Aplicar prefer√™ncias de reuni√£o tanto em contextos de calend√°rio quanto de email\n",
    "- Capturar nuance com qualificadores apropriados (\"quando poss√≠vel\", \"a menos que especificado de outra forma\")\n",
    "- Manter a estrutura hier√°rquica da mem√≥ria\n",
    "\n",
    "O email resultante mostra todas essas prefer√™ncias aplicadas: √© mais curto, menos formal, inclui uma declara√ß√£o de encerramento sobre esperar pela conversa, e referencia corretamente o hor√°rio de reuni√£o de 30 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulando usu√°rio aceitando a {Interrupt_Object.value[0]['action_request']['action']} chamada de ferramenta...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nOBJETO DE INTERRUP√á√ÉO:\")\n",
    "        print(f\"Solicita√ß√£o de A√ß√£o: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after feedback\n",
    "print(\"\\nVerificando mem√≥ria ap√≥s aceitar write_email ap√≥s feedback:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e63cb",
   "metadata": {},
   "source": [
    "Olhar o hist√≥rico completo de mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_5)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac9df0-cd39-4c32-a073-c2482d9554b6",
   "metadata": {},
   "source": [
    "## Local Deployment\n",
    "\n",
    "You can find this graph with memory integration in the `src/email_assistant` directory:\n",
    "\n",
    "* `src/email_assistant/email_assistant_hitl_memory.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4aa8b0-f8b7-4197-8701-87dda60daa26",
   "metadata": {},
   "source": [
    "Email to test: \n",
    "```\n",
    "{\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}\n",
    "```\n",
    "\n",
    "As before, if you go to [dev.agentinbox.ai](https://dev.agentinbox.ai/), you can easily connect to the graph:\n",
    "\n",
    "   * Graph name: the name from the `langgraph.json` file (`email_assistant_hitl_memory`)\n",
    "   * Graph URL: `http://127.0.0.1:2024/`\n",
    "\n",
    "![inbox](img/agent-inbox-edit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075a3ea",
   "metadata": {},
   "source": [
    "The Memory tab in LangGraph Studio offers a real-time view of how your preferences are being captured and updated with each interaction:\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "Through continued use, the system becomes increasingly personalized:\n",
    "- It learns which emails you want to respond to, be notified about, or ignore\n",
    "- It adapts to your communication style preferences\n",
    "- It remembers your scheduling preferences\n",
    "- It refines its understanding with each interaction\n",
    "\n",
    "This combination of HITL and memory creates a system that balances automation with control - handling routine tasks automatically while learning from your feedback to become more aligned with your preferences over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad7580",
   "metadata": {},
   "source": [
    "## Hosted Deployment with Gmail Tools\n",
    "\n",
    "If you want to actually run this on your own email, you can deploy the graph with Gmail tools. \n",
    "\n",
    "Set up your Gmail credentials [following here](https://github.com/langchain-ai/agents-from-scratch/blob/main/src/email_assistant/tools/gmail/README.md).\n",
    "\n",
    "There is a graph set up with Gmail tools:\n",
    "\n",
    "```shell\n",
    "python src/email_assistant/email_assistant_hitl_memory_gmail.py\n",
    "```\n",
    "\n",
    "[One of the deployment options is `hosted`](https://langchain-ai.github.io/langgraph/tutorials/deployment/#other-deployment-options), and you can simply connect the deployed graph URL to the Agent Inbox as done with the local deployment.\n",
    "\n",
    "## Improving Memory \n",
    "\n",
    "Our current memory schema and updating is extremely simple: \n",
    "\n",
    "* Our schema is a string\n",
    "* We always overwrite the existing memory with a new string\n",
    " \n",
    "The store can be easily [configured for semantic search](https://langchain-ai.github.io/langgraph/cloud/deployment/semantic_search/) over a collection of memories. \n",
    "\n",
    "Also consider using [LangMem](https://langchain-ai.github.io/langmem/) for more advanced memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dbb9b-5c9a-4236-912e-02b3d9f674f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
